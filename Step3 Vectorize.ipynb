{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "6bd3622f6f3f8bb6e8b4643a72dc4bf7a75a1467dea0f2ef918aabb1c737dfb1"
   }
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Step 3: Vectorize\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Type IE NS FT PJ                                   Posts_Lemmatized\n",
       "0  INFJ  I  N  F  J  [, moment, sportscenter, top, ten, play, prank...\n",
       "1  ENTP  E  N  T  P  [finding, lack, post, alarming, sex, boring, p...\n",
       "2  INTP  I  N  T  P  [good, one, course, say, know, blessing, curse...\n",
       "3  INTJ  I  N  T  J  [dear, enjoyed, conversation, day, esoteric, g...\n",
       "4  ENTJ  E  N  T  J  [fired, another, silly, misconception, approac..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>IE</th>\n      <th>NS</th>\n      <th>FT</th>\n      <th>PJ</th>\n      <th>Posts_Lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>I</td>\n      <td>N</td>\n      <td>F</td>\n      <td>J</td>\n      <td>[, moment, sportscenter, top, ten, play, prank...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>E</td>\n      <td>N</td>\n      <td>T</td>\n      <td>P</td>\n      <td>[finding, lack, post, alarming, sex, boring, p...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>I</td>\n      <td>N</td>\n      <td>T</td>\n      <td>P</td>\n      <td>[good, one, course, say, know, blessing, curse...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>I</td>\n      <td>N</td>\n      <td>T</td>\n      <td>J</td>\n      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>E</td>\n      <td>N</td>\n      <td>T</td>\n      <td>J</td>\n      <td>[fired, another, silly, misconception, approac...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "#Clean up memory from any values\n",
    "for name in dir():\n",
    "    if not name.startswith('_'):\n",
    "        del globals()[name]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "#Reading data from step 2\n",
    "fields = ['Type', 'IE', 'NS', 'FT', 'PJ', 'Posts_Lemmatized']\n",
    "mbti_Dataset = pd.read_pickle('mbti_Dataset2.pkl')\n",
    "mbti_Dataset = mbti_Dataset.filter(fields)\n",
    "mbti_Dataset.head()"
   ]
  },
  {
   "source": [
    "## 3-1: Count Vectorization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "List of first 50 features: \n ['', 'a', 'abandoned', 'ability', 'able', 'abrupt', 'absence', 'absolute', 'absolutely', 'absolutezero', 'absurd', 'abuse', 'accepted', 'accident', 'accomplished', 'according', 'accurate', 'ace', 'achieving', 'acid', 'acknowledge', 'acknowledging', 'acoustic', 'act', 'action', 'actress', 'actual', 'actually', 'acutely', 'add', 'addictive', 'address', 'admiration', 'admit', 'adobe', 'advancement', 'advent', 'adventure', 'advice', 'advocate', 'affair', 'affect', 'affectionate', 'age', 'aggressive', 'ago', 'agonizingly', 'agree', 'agreed', 'agreement']\n\nList of last 50 features: \n ['worka', 'worked', 'workin', 'working', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'worthwhile', 'would', 'wow', 'wrath', 'wrestling', 'writer', 'writing', 'written', 'wrong', 'wrote', 'wylde', 'x', 'xbox', 'xd', 'xfiles', 'xingkes', 'xtctr', 'xxfps', 'ya', 'yeah', 'year', 'yearold', 'yeehaw', 'yellow', 'yep', 'yes', 'yet', 'yikes', 'yippy', 'yo', 'young', 'younger', 'youtubing', 'yr', 'yup', 'zakk', 'zombie', 'zone', 'zoom', 'â']\n\n Sample Shape(CountVectorizer) :  (11, 2448)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def lemmatizing(text):\n",
    "    \"\"\"Lemmatizing the input text using WordNet and NLTK package\"\"\"\n",
    "    NLTK_WNL = nltk.WordNetLemmatizer()\n",
    "    text_Lem = [NLTK_WNL.lemmatize(word) for word in text]\n",
    "    return(text_Lem)\n",
    "\n",
    "\n",
    "#Sample 10 first rows of the data and copy it to a temp dataset to be able to validate the result better\n",
    "small_Data = mbti_Dataset.loc[0:10,['Posts_Lemmatized']]\n",
    "small_countvec = CountVectorizer(analyzer=lemmatizing)\n",
    "small_Lem_CV = small_countvec.fit_transform(small_Data['Posts_Lemmatized'])\n",
    "\n",
    "print('List of first 50 features: \\n', small_countvec.get_feature_names()[0:50])\n",
    "print('\\nList of last 50 features: \\n', small_countvec.get_feature_names()[-50:])\n",
    "print('\\n Sample Shape(CountVectorizer) : ', small_Lem_CV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       a  abandoned  ability  able  abrupt  absence  absolute  absolutely  \\\n",
       "0   1  0          0        0     0       0        0         0           0   \n",
       "1   0  0          1        0     1       0        0         0           0   \n",
       "2   1  0          0        2     1       1        0         0           2   \n",
       "3   0  0          0        0     2       0        0         1           0   \n",
       "4   0  1          0        0     0       0        0         0           0   \n",
       "5   1  0          0        0     1       0        0         0           0   \n",
       "6   0  0          0        0     1       0        1         0           0   \n",
       "7   0  0          0        0     0       0        0         0           0   \n",
       "8   1  0          0        0     0       0        0         0           0   \n",
       "9   1  0          0        0     0       0        0         0           2   \n",
       "10  0  0          1        0     0       0        0         0           1   \n",
       "\n",
       "    absolutezero  ...  young  younger  youtubing  yr  yup  zakk  zombie  zone  \\\n",
       "0              0  ...      0        0          0   0    0     0       0     0   \n",
       "1              0  ...      0        0          0   0    0     0       0     0   \n",
       "2              0  ...      0        0          0   0    1     0       0     0   \n",
       "3              0  ...      0        0          0   0    0     0       0     0   \n",
       "4              0  ...      0        0          0   0    0     0       0     0   \n",
       "5              0  ...      0        0          0   0    0     0       0     0   \n",
       "6              0  ...      1        0          0   1    0     0       0     1   \n",
       "7              0  ...      0        0          0   0    0     0       0     0   \n",
       "8              0  ...      0        0          0   0    0     1       0     0   \n",
       "9              1  ...      0        0          1   0    0     0       0     0   \n",
       "10             0  ...      0        1          0   0    0     0       1     0   \n",
       "\n",
       "    zoom  â  \n",
       "0      0  0  \n",
       "1      0  0  \n",
       "2      0  1  \n",
       "3      0  0  \n",
       "4      0  0  \n",
       "5      0  0  \n",
       "6      1  0  \n",
       "7      0  0  \n",
       "8      0  0  \n",
       "9      0  0  \n",
       "10     0  0  \n",
       "\n",
       "[11 rows x 2448 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>a</th>\n      <th>abandoned</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>abrupt</th>\n      <th>absence</th>\n      <th>absolute</th>\n      <th>absolutely</th>\n      <th>absolutezero</th>\n      <th>...</th>\n      <th>young</th>\n      <th>younger</th>\n      <th>youtubing</th>\n      <th>yr</th>\n      <th>yup</th>\n      <th>zakk</th>\n      <th>zombie</th>\n      <th>zone</th>\n      <th>zoom</th>\n      <th>â</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows × 2448 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "small_Lem_DF = pd.DataFrame(small_Lem_CV.toarray())\n",
    "small_Lem_DF.columns = small_countvec.get_feature_names()\n",
    "small_Lem_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of CountVectorizer(full dataset):   (8675, 135767)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Running CountVectorizer on full dataset\n",
    "count_Vec = CountVectorizer(analyzer=lemmatizing)\n",
    "full_Lem_CV = count_Vec.fit_transform(mbti_Dataset['Posts_Lemmatized'])\n",
    "\n",
    "print('Shape of CountVectorizer(full dataset):  ',full_Lem_CV.shape)"
   ]
  },
  {
   "source": [
    "## 3-2: N-gram Vectorizing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "List of first 50 features: \n ['abandoned', 'abandoned building', 'abandoned building old', 'abandoned ni', 'abandoned ni age', 'ability', 'ability generate', 'ability generate idea', 'ability give', 'ability give birth', 'able', 'able build', 'able build building', 'able lol', 'able look', 'able look painting', 'able read', 'able read interpret', 'able relate', 'able relate feeling', 'able stop', 'able stop started', 'abrupt', 'abrupt explosion', 'abrupt explosion laughter', 'absence', 'absence religion', 'absence religion people', 'absolute', 'absolute admiration', 'absolute admiration refreshing', 'absolutely', 'absolutely know', 'absolutely know tf', 'absolutely love', 'absolutely love true', 'absolutely neutral', 'absolutely neutral face', 'absolutely positive', 'absolutely positive best', 'absolutely terrifies', 'absolutely terrifies lose', 'absolutezero', 'absolutezero comprehension', 'absolutezero comprehension requiring', 'absurd', 'absurd thing', 'absurd thing like', 'abuse', 'abuse friend']\n\nList of last 50 features: \n ['yes said type', 'yes sinking', 'yes sinking feeling', 'yes useful', 'yes useful thought', 'yes warrant', 'yes warrant validate', 'yes would', 'yes would say', 'yet', 'yet need', 'yet need longer', 'yikes', 'yikes mother', 'yikes mother thought', 'yippy', 'yippy go', 'yippy go think', 'yo', 'yo lady', 'yo lady complimentary', 'yo self', 'yo self question', 'young', 'young would', 'young would wake', 'younger', 'younger brother', 'younger brother entire', 'youtubing', 'youtubing entire', 'youtubing entire thing', 'yr', 'yr broke', 'yr broke cry', 'yup', 'yup right', 'yup right course', 'zakk', 'zakk wylde', 'zakk wylde musical', 'zombie', 'zombie moth', 'zombie moth attracted', 'zone', 'zone sake', 'zone sake emotional', 'zoom', 'zoom fact', 'zoom fact question']\n\n Sample Shape for 3-grams:  (11, 13881)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Sample 10 first rows of the data and copy it to a temp dataset to be able to validate the result better\n",
    "small_Data = mbti_Dataset.loc[0:10,['Type','Posts_Lemmatized']]\n",
    "small_Ngram = CountVectorizer(ngram_range=(1,3))#Max N-Gram is set to 3\n",
    "temp_Dataset = small_Data['Posts_Lemmatized'].apply(lambda x: ' '.join(map(str,x)))\n",
    "small_Lem_Ngram = small_Ngram.fit_transform(temp_Dataset)\n",
    "\n",
    "print('List of first 50 features: \\n', small_Ngram.get_feature_names()[0:50])\n",
    "print('\\nList of last 50 features: \\n', small_Ngram.get_feature_names()[-50:])\n",
    "print('\\n Sample Shape for 3-grams: ', small_Lem_Ngram.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    abandoned  abandoned building  abandoned building old  abandoned ni  \\\n",
       "0           0                   0                       0             0   \n",
       "1           1                   1                       1             0   \n",
       "2           0                   0                       0             0   \n",
       "3           0                   0                       0             0   \n",
       "4           0                   0                       0             0   \n",
       "5           0                   0                       0             0   \n",
       "6           0                   0                       0             0   \n",
       "7           0                   0                       0             0   \n",
       "8           0                   0                       0             0   \n",
       "9           0                   0                       0             0   \n",
       "10          1                   0                       0             1   \n",
       "\n",
       "    abandoned ni age  ability  ability generate  ability generate idea  \\\n",
       "0                  0        0                 0                      0   \n",
       "1                  0        0                 0                      0   \n",
       "2                  0        2                 1                      1   \n",
       "3                  0        0                 0                      0   \n",
       "4                  0        0                 0                      0   \n",
       "5                  0        0                 0                      0   \n",
       "6                  0        0                 0                      0   \n",
       "7                  0        0                 0                      0   \n",
       "8                  0        0                 0                      0   \n",
       "9                  0        0                 0                      0   \n",
       "10                 1        0                 0                      0   \n",
       "\n",
       "    ability give  ability give birth  ...  zakk wylde musical  zombie  \\\n",
       "0              0                   0  ...                   0       0   \n",
       "1              0                   0  ...                   0       0   \n",
       "2              1                   1  ...                   0       0   \n",
       "3              0                   0  ...                   0       0   \n",
       "4              0                   0  ...                   0       0   \n",
       "5              0                   0  ...                   0       0   \n",
       "6              0                   0  ...                   0       0   \n",
       "7              0                   0  ...                   0       0   \n",
       "8              0                   0  ...                   1       0   \n",
       "9              0                   0  ...                   0       0   \n",
       "10             0                   0  ...                   0       1   \n",
       "\n",
       "    zombie moth  zombie moth attracted  zone  zone sake  zone sake emotional  \\\n",
       "0             0                      0     0          0                    0   \n",
       "1             0                      0     0          0                    0   \n",
       "2             0                      0     0          0                    0   \n",
       "3             0                      0     0          0                    0   \n",
       "4             0                      0     0          0                    0   \n",
       "5             0                      0     0          0                    0   \n",
       "6             0                      0     1          1                    1   \n",
       "7             0                      0     0          0                    0   \n",
       "8             0                      0     0          0                    0   \n",
       "9             0                      0     0          0                    0   \n",
       "10            1                      1     0          0                    0   \n",
       "\n",
       "    zoom  zoom fact  zoom fact question  \n",
       "0      0          0                   0  \n",
       "1      0          0                   0  \n",
       "2      0          0                   0  \n",
       "3      0          0                   0  \n",
       "4      0          0                   0  \n",
       "5      0          0                   0  \n",
       "6      1          1                   1  \n",
       "7      0          0                   0  \n",
       "8      0          0                   0  \n",
       "9      0          0                   0  \n",
       "10     0          0                   0  \n",
       "\n",
       "[11 rows x 13881 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abandoned</th>\n      <th>abandoned building</th>\n      <th>abandoned building old</th>\n      <th>abandoned ni</th>\n      <th>abandoned ni age</th>\n      <th>ability</th>\n      <th>ability generate</th>\n      <th>ability generate idea</th>\n      <th>ability give</th>\n      <th>ability give birth</th>\n      <th>...</th>\n      <th>zakk wylde musical</th>\n      <th>zombie</th>\n      <th>zombie moth</th>\n      <th>zombie moth attracted</th>\n      <th>zone</th>\n      <th>zone sake</th>\n      <th>zone sake emotional</th>\n      <th>zoom</th>\n      <th>zoom fact</th>\n      <th>zoom fact question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows × 13881 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "small_Ngram_DF = pd.DataFrame(small_Lem_Ngram.toarray())\n",
    "small_Ngram_DF.columns = small_Ngram.get_feature_names()\n",
    "small_Ngram_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of 3-Grams(full dataset): (8675, 7157205)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Running N-Gram on full dataset (Max = 3)\n",
    "full_Ngram = CountVectorizer(ngram_range=(1,3))\n",
    "temp_Dataset = mbti_Dataset['Posts_Lemmatized'].apply(lambda x: ' '.join(map(str,x)))\n",
    "full_Lem_Ngram = full_Ngram.fit_transform(temp_Dataset)\n",
    "\n",
    "print('Shape of 3-Grams(full dataset):', full_Lem_Ngram.shape)\n"
   ]
  },
  {
   "source": [
    "## 3-3: Invers Document Frequency Weighting\n",
    "####        tf-idf(t, d) = tf(t, d) * log(N/(df + 1))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "List of first 50 features: \n ['', 'a', 'abandoned', 'ability', 'able', 'abrupt', 'absence', 'absolute', 'absolutely', 'absolutezero', 'absurd', 'abuse', 'accepted', 'accident', 'accomplished', 'according', 'accurate', 'ace', 'achieving', 'acid', 'acknowledge', 'acknowledging', 'acoustic', 'act', 'action', 'actress', 'actual', 'actually', 'acutely', 'add', 'addictive', 'address', 'admiration', 'admit', 'adobe', 'advancement', 'advent', 'adventure', 'advice', 'advocate', 'affair', 'affect', 'affectionate', 'age', 'aggressive', 'ago', 'agonizingly', 'agree', 'agreed', 'agreement']\n\nList of last 50 features: \n ['worka', 'worked', 'workin', 'working', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'worthwhile', 'would', 'wow', 'wrath', 'wrestling', 'writer', 'writing', 'written', 'wrong', 'wrote', 'wylde', 'x', 'xbox', 'xd', 'xfiles', 'xingkes', 'xtctr', 'xxfps', 'ya', 'yeah', 'year', 'yearold', 'yeehaw', 'yellow', 'yep', 'yes', 'yet', 'yikes', 'yippy', 'yo', 'young', 'younger', 'youtubing', 'yr', 'yup', 'zakk', 'zombie', 'zone', 'zoom', 'â']\n\n Shape for TFIDF Vectorizer(Sample):  (11, 2448)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Sample 10 first rows of the data and copy it to a temp dataset to be able to validate the result better\n",
    "small_Data = mbti_Dataset.loc[0:10,['Type','Posts_Lemmatized']]\n",
    "small_TFIDF = TfidfVectorizer(analyzer=lemmatizing)\n",
    "small_Lem_TFIDF = small_TFIDF.fit_transform(small_Data['Posts_Lemmatized'])\n",
    "\n",
    "print('List of first 50 features: \\n', small_TFIDF.get_feature_names()[0:50])\n",
    "print('\\nList of last 50 features: \\n', small_TFIDF.get_feature_names()[-50:])\n",
    "print('\\n Shape for TFIDF Vectorizer(Sample): ', small_Lem_TFIDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     a  abandoned   ability      able    abrupt   absence  \\\n",
       "0   0.035998  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000   0.035859  0.000000  0.025443  0.000000  0.000000   \n",
       "2   0.031991  0.000000   0.000000  0.105497  0.031991  0.052748  0.000000   \n",
       "3   0.000000  0.000000   0.000000  0.000000  0.054287  0.000000  0.000000   \n",
       "4   0.000000  0.047334   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.022506  0.000000   0.000000  0.000000  0.022506  0.000000  0.000000   \n",
       "6   0.000000  0.000000   0.000000  0.000000  0.023029  0.000000  0.037972   \n",
       "7   0.000000  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.035119  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.023738  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000   0.030982  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "    absolute  absolutely  absolutezero  ...     young   younger  youtubing  \\\n",
       "0   0.000000    0.000000      0.000000  ...  0.000000  0.000000   0.000000   \n",
       "1   0.000000    0.000000      0.000000  ...  0.000000  0.000000   0.000000   \n",
       "2   0.000000    0.079304      0.000000  ...  0.000000  0.000000   0.000000   \n",
       "3   0.044755    0.000000      0.000000  ...  0.000000  0.000000   0.000000   \n",
       "4   0.000000    0.000000      0.000000  ...  0.000000  0.000000   0.000000   \n",
       "5   0.000000    0.000000      0.000000  ...  0.000000  0.000000   0.000000   \n",
       "6   0.000000    0.000000      0.000000  ...  0.037972  0.000000   0.000000   \n",
       "7   0.000000    0.000000      0.000000  ...  0.000000  0.000000   0.000000   \n",
       "8   0.000000    0.000000      0.000000  ...  0.000000  0.000000   0.000000   \n",
       "9   0.000000    0.058846      0.039141  ...  0.000000  0.000000   0.039141   \n",
       "10  0.000000    0.027247      0.000000  ...  0.000000  0.036247   0.000000   \n",
       "\n",
       "          yr       yup      zakk    zombie      zone      zoom         â  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.052748  0.000000  0.000000  0.000000  0.000000  0.052748  \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6   0.037972  0.000000  0.000000  0.000000  0.037972  0.037972  0.000000  \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8   0.000000  0.000000  0.057906  0.000000  0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "10  0.000000  0.000000  0.000000  0.036247  0.000000  0.000000  0.000000  \n",
       "\n",
       "[11 rows x 2448 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>a</th>\n      <th>abandoned</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>abrupt</th>\n      <th>absence</th>\n      <th>absolute</th>\n      <th>absolutely</th>\n      <th>absolutezero</th>\n      <th>...</th>\n      <th>young</th>\n      <th>younger</th>\n      <th>youtubing</th>\n      <th>yr</th>\n      <th>yup</th>\n      <th>zakk</th>\n      <th>zombie</th>\n      <th>zone</th>\n      <th>zoom</th>\n      <th>â</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.035998</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.035859</td>\n      <td>0.000000</td>\n      <td>0.025443</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.031991</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.105497</td>\n      <td>0.031991</td>\n      <td>0.052748</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.079304</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.052748</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.052748</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.054287</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.044755</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.047334</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.022506</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.022506</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.023029</td>\n      <td>0.000000</td>\n      <td>0.037972</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.037972</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.037972</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.037972</td>\n      <td>0.037972</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.035119</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.057906</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.023738</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.058846</td>\n      <td>0.039141</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.039141</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.030982</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.027247</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.036247</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.036247</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows × 2448 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "small_TFIDF_DF = pd.DataFrame(small_Lem_TFIDF.toarray())\n",
    "small_TFIDF_DF.columns = small_TFIDF.get_feature_names()\n",
    "small_TFIDF_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of TFIDF(full dataset): (8675, 135767)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Running TFIDF on full dataset\n",
    "vectorizer_TFIDF = TfidfVectorizer(analyzer=lemmatizing)\n",
    "full_Lem_tfidf = vectorizer_TFIDF.fit_transform(mbti_Dataset['Posts_Lemmatized'])\n",
    "\n",
    "print('Shape of TFIDF(full dataset):', full_Lem_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "#Saving the results into npz file\n",
    "sparse.save_npz('full_Lem_Count.npz', full_Lem_CV)\n",
    "sparse.save_npz('full_Lem_Ngram.npz', full_Lem_Ngram)\n",
    "sparse.save_npz('full_Lem_TFIDF.npz', full_Lem_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}