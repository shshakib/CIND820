{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2: Gradient Boosting Model\n",
    "### 5-2-1: Gradient Boosting with Holdout test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\r\n",
    "#from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "\r\n",
    "pd.set_option('display.max_rows', None, 'display.max_colwidth', 500)\r\n",
    "\r\n",
    "\r\n",
    "def GBoosting_GridSearch(Lable, n_est, depth, lr, feature_type, is_print = True):\r\n",
    "    if Lable == 'IE':\r\n",
    "        s_Lable = 'I'\r\n",
    "        predict_Lable = 'Introverts'\r\n",
    "    elif Lable == 'NS':\r\n",
    "        s_Lable = 'N'\r\n",
    "        predict_Lable = 'Intuitives'\r\n",
    "    elif Lable == 'FT':\r\n",
    "        s_Lable = 'F'\r\n",
    "        predict_Lable = 'Feelers'\r\n",
    "    elif Lable == 'PJ':\r\n",
    "        s_Lable = 'P'\r\n",
    "        predict_Lable = 'Perceivers'\r\n",
    "\r\n",
    "    gb = GradientBoostingClassifier(n_estimators=n_est, max_depth=depth , learning_rate=lr)\r\n",
    "    gb_model = gb.fit(X_train_set, Y_train[Lable])\r\n",
    "    Y_pred = gb_model.predict(X_test_set)\r\n",
    "\r\n",
    "    precision, recall, fscore, support = score(Y_test[Lable], Y_pred, pos_label=s_Lable, average='binary')\r\n",
    "    if is_print:\r\n",
    "        print('Being ' + predict_Lable + ' using ' + feature_type + ': '  ,'Estimators: {} / Max_Depth: {} / Learning_Rate: {} --> Precision: {} / Recall: {} / Accuracy: {}'.format(\r\n",
    "                                                        n_est,\r\n",
    "                                                        depth,\r\n",
    "                                                        lr,\r\n",
    "                                                        round(precision, 3),\r\n",
    "                                                        round(recall, 3), \r\n",
    "                                                        round((Y_pred==Y_test[Lable]).sum() / len(Y_pred),3)))\r\n",
    "    return([predict_Lable, feature_type, n_est, depth, lr, precision, recall, round((Y_pred==Y_test[Lable]).sum() / len(Y_pred),3)])\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "classes = ['FT']\r\n",
    "gb_result = []\r\n",
    "\r\n",
    "Y_train = pd.read_pickle('Y_train.pkl')\r\n",
    "Y_test = pd.read_pickle('Y_test.pkl')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "for feature_type in ['TFIDF', 'CountVectorizer']:\r\n",
    "    if feature_type == 'TFIDF':\r\n",
    "        X_test_set = np.load('X_test_tfidf.npy')\r\n",
    "        X_train_set = np.load('X_train_tfidf.npy')\r\n",
    "    elif feature_type == 'CountVectorizer':\r\n",
    "        X_test_set = np.load('X_test_count.npy')\r\n",
    "        X_train_set = np.load('X_train_count.npy')\r\n",
    "    #elif feature_type == 'N-gram':\r\n",
    "        #X_test_set = np.load('X_test_ngram.npy')\r\n",
    "        #X_train_set = np.load('X_train_ngram.npy')\r\n",
    "        #print()\r\n",
    "    for item in classes:\r\n",
    "        for n_est in [50, 100, 150]:\r\n",
    "            for depth in [3, 7, 11, 15]:\r\n",
    "                for lr in [0.01, 0.10, 1.00]:\r\n",
    "                    gb_result.append(GBoosting_GridSearch(Lable = item, n_est=n_est, depth=depth, lr = lr, feature_type=feature_type))\r\n",
    "                    pd.DataFrame(gb_result, columns= ['Type', 'Method', 'Estimators', 'Max_Depth', 'Learning_Rate','Precision', 'Recall', 'Accuracy']).to_csv('GB_Holdout_Result.csv')\r\n",
    "\r\n",
    "pd.DataFrame(gb_result, columns= ['Type', 'Method', 'Estimators', 'Max_Depth', 'Learning_Rate','Precision', 'Recall', 'Accuracy']).to_csv('GB_Holdout_Result.csv')\r\n",
    "#pd.DataFrame(gb_result, columns= ['Type', 'Method', 'Estimators', 'Max_Depth', 'Learning_Rate','Precision', 'Recall', 'Accuracy']).head()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2-2: Evaluation Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "pd.set_option('display.max_colwidth', 500)\r\n",
    "\r\n",
    "\r\n",
    "def GB_Evaluation(param, Lable, is_print = True):\r\n",
    "    gb = GradientBoostingClassifier()\r\n",
    "    gs = GridSearchCV(gb, param, cv=5)#cv=5 meand 5 folde validation\r\n",
    "    gs_fit = gs.fit(X_train_set, Y_train[Lable])\r\n",
    "\r\n",
    "    if is_print:\r\n",
    "        print(pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[['param_max_depth', \r\n",
    "        'param_n_estimators', 'param_learning_rate','std_test_score', 'mean_test_score', 'rank_test_score']][0:5])\r\n",
    "\r\n",
    "    return(pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[['param_max_depth',\r\n",
    "     'param_n_estimators', 'param_learning_rate', 'std_test_score', 'mean_test_score', 'rank_test_score']][0:5])\r\n",
    "  \r\n",
    "param = {'n_estimators' : [50, 100, 150],\r\n",
    "                'max_depth' : [7, 11, 15],\r\n",
    "                'learning_rate' : [0.1,0.25]}\r\n",
    "\r\n",
    "classes = ['IE' , 'NS', 'FT', 'PJ']\r\n",
    "Y_train = pd.read_pickle('Y_train.pkl')\r\n",
    "gb_parm_result = []\r\n",
    "\r\n",
    "\r\n",
    "for feature_type in ['TFIDF', 'CountVectorizer']:\r\n",
    "    if feature_type == 'TFIDF':\r\n",
    "        X_train_set = np.load('X_train_tfidf.npy')\r\n",
    "    elif feature_type == 'CountVectorizer':\r\n",
    "        X_train_set = np.load('X_train_count.npy')\r\n",
    "    #elif feature_type == 'N-gram':\r\n",
    "        #X_train_set = np.load('X_train_ngram.npy')\r\n",
    "    for item in classes:\r\n",
    "        gb_parm_result.append(GB_Evaluation(param = param, Lable = item))\r\n",
    "\r\n",
    "pd.DataFrame(gb_parm_result).to_csv('GB_Parm_Result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introverts --> Fit time: 15.922 / Predict time: 0.686 --> Estimator 10 / Max_Depth 30.0 --> Precision: 0.755 / Recall: 0.997 / Accuracy: 0.754\n",
      "Feelers --> Fit time: 293.472 / Predict time: 1.353 --> Estimator 500 / Max_Depth None --> Precision: 0.731 / Recall: 0.896 / Accuracy: 0.761\n",
      "Perceivers --> Fit time: 90.712 / Predict time: 1.005 --> Estimator 100 / Max_Depth None --> Precision: 0.644 / Recall: 0.964 / Accuracy: 0.646\n",
      "Intuitives --> Fit time: 38.441 / Predict time: 0.698 --> Estimator 10 / Max_Depth None --> Precision: 0.856 / Recall: 0.999 / Accuracy: 0.855\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\r\n",
    "import time\r\n",
    "import math\r\n",
    "\r\n",
    "Y_train = pd.read_pickle('Y_train.pkl')\r\n",
    "Y_test = pd.read_pickle('Y_test.pkl')\r\n",
    "X_train_tfidf = np.load('X_train_tfidf.npy')\r\n",
    "X_test_tfidf = np.load('X_test_tfidf.npy')\r\n",
    "\r\n",
    "df = pd.read_csv('RF_Parm_Result.csv')\r\n",
    "df = df.sort_values(['rank_test_score'], ascending = True).groupby(['Class']).head(1)\r\n",
    "\r\n",
    "def RF_Final_Eval(item):\r\n",
    "    if item['Class'] == 'IE':\r\n",
    "        Lable, s_Lable, predict_Lable = 'IE', 'I', 'Introverts'\r\n",
    " \r\n",
    "    elif item['Class'] == 'NS':\r\n",
    "        Lable, s_Lable, predict_Lable = 'NS', 'N', 'Intuitives'\r\n",
    "\r\n",
    "    elif item['Class'] == 'FT':\r\n",
    "        Lable, s_Lable, predict_Lable = 'FT','F', 'Feelers'\r\n",
    "\r\n",
    "    elif item['Class'] == 'PJ':\r\n",
    "        Lable, s_Lable, predict_Lable = 'PJ','P', 'Perceivers'\r\n",
    "    \r\n",
    "    if math.isnan(item['param_max_depth']):\r\n",
    "        item['param_max_depth'] = None\r\n",
    "\r\n",
    "    rf = RandomForestClassifier(n_estimators=item['param_n_estimators'], max_depth=item['param_max_depth'], n_jobs=-1)\r\n",
    "\r\n",
    "    start = time.time()\r\n",
    "    rf_model = rf.fit(X_train_tfidf, Y_train[Lable])\r\n",
    "    end = time.time()\r\n",
    "    fit_time = (end - start)\r\n",
    "\r\n",
    "    start = time.time()\r\n",
    "    Y_pred = rf_model.predict(X_test_tfidf)\r\n",
    "    end = time.time()\r\n",
    "    pred_time = (end - start)\r\n",
    "\r\n",
    "    precision, recall, fscore, train_support = score(Y_test[Lable], Y_pred, pos_label=s_Lable, average='binary')\r\n",
    "\r\n",
    "    print('{} --> Fit time: {} / Predict time: {} --> Estimator {} / Max_Depth {} --> Precision: {} / Recall: {} / Accuracy: {}'.format(\r\n",
    "                                                    predict_Lable,\r\n",
    "                                                    round(fit_time, 3),\r\n",
    "                                                    round(pred_time, 3),\r\n",
    "                                                    item['param_n_estimators'],\r\n",
    "                                                    item['param_max_depth'],\r\n",
    "                                                    round(precision, 3),\r\n",
    "                                                    round(recall, 3), \r\n",
    "                                                    round((Y_pred==Y_test[Lable]).sum() / len(Y_pred),3)))\r\n",
    "\r\n",
    "\r\n",
    "for index, item in df.iterrows():\r\n",
    "    RF_Final_Eval(item)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\r\n",
    "import time\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "classes = ['IE' , 'NS', 'FT', 'PJ']\r\n",
    "Y_train = pd.read_pickle('Y_train.pkl')\r\n",
    "Y_test = pd.read_pickle('Y_test.pkl')\r\n",
    "X_train_tfidf = np.load('X_train_tfidf.npy')\r\n",
    "X_test_tfidf = np.load('X_test_tfidf.npy')\r\n",
    "\r\n",
    "df = pd.read_csv('GB_Parm_Result.csv')\r\n",
    "df = df.sort_values(['rank_test_score'], ascending = True).groupby(['Class']).head(1)\r\n",
    "\r\n",
    "for index, item in df.iterrows():\r\n",
    "    if item['Class'] == 'IE':\r\n",
    "        s_Lable = 'I'\r\n",
    "    elif item['Class'] == 'NS':\r\n",
    "        s_Lable = 'N'\r\n",
    "    elif item['Class'] == 'FT':\r\n",
    "        s_Lable = 'F'\r\n",
    "    elif item['Class'] == 'PJ':\r\n",
    "        s_Lable = 'P'\r\n",
    "\r\n",
    "    \r\n",
    "    gb = GradientBoostingClassifier(n_estimators=item['param_n_estimators'], max_depth=item['param_max_depth'], lr=)\r\n",
    "\r\n",
    "    start = time.time()\r\n",
    "    gb_model = gb.fit(X_train_tfidf,Y_train[])\r\n",
    "    end = time.time()\r\n",
    "    fit_time = (end - start)\r\n",
    "\r\n",
    "    start = time.time()\r\n",
    "    Y_pred = gb_model.predict(X_test_tfidf)\r\n",
    "    end = time.time()\r\n",
    "    pred_time = (end - start)\r\n",
    "\r\n",
    "\r\n",
    "precision, recall, fscore, train_support = score(Y_test[Lable], Y_pred, pos_label=s_Lable, average='binary')\r\n",
    "\r\n",
    "print('Fit time: {} / Predict time: {} --> Precision: {} / Recall: {} / Accuracy: {}'.format(\r\n",
    "                                                        round(fit_time, 3),\r\n",
    "                                                        round(pred_time, 3),\r\n",
    "                                                        round(precision, 3),\r\n",
    "                                                        round(recall, 3), \r\n",
    "                                                        round((Y_pred==Y_test[Lable]).sum() / len(Y_pred),3)))\r\n",
    "                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "6bd3622f6f3f8bb6e8b4643a72dc4bf7a75a1467dea0f2ef918aabb1c737dfb1"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}