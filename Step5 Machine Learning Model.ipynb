{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "6bd3622f6f3f8bb6e8b4643a72dc4bf7a75a1467dea0f2ef918aabb1c737dfb1"
   }
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Setep 5: Machine Learning Model\n",
    "\n",
    "### 5-1: Random Forest Model\n",
    "<br>\n",
    "1- Can be used for Classification or Regression<br>\n",
    "2- Easily handles outliers, missing values, etc.<br>\n",
    "3- Accepts various types of inputs (continues, ordinal, ...)<br>\n",
    "4- Less likely to overfit<br>\n",
    "5- Outputs feature importance<br>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load information from prevous steps\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "mbti_Dataset = pd.read_csv('mbti_Dataset.csv')\n",
    "mbti_FE = pd.read_csv('mbti_FE.csv')\n",
    "\n",
    "full_Lem_CV = sparse.load_npz('full_Lem_CV.npz')\n",
    "full_Lem_Ngram = sparse.load_npz('full_Lem_Ngram.npz')\n",
    "full_Lem_tfidf = sparse.load_npz('full_Lem_tfidf.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick clean up\n",
    "for name in dir():\n",
    "    if not name.startswith('_') and name not in ['mbti_FE','mbti_Dataset', 'full_Lem_CV', 'full_Lem_Ngram', 'full_Lem_tfidf']:\n",
    "        del globals()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Count Vectorization\n",
      "Count Vectorization for IE [0.7740634  0.77233429 0.75677233 0.77694524 0.77175793]\n",
      "Count Vectorization for NS [0.86801153 0.85475504 0.86916427 0.85994236 0.85878963]\n",
      "Count Vectorization for FT [0.73256484 0.72391931 0.71873199 0.73198847 0.71585014]\n",
      "Count Vectorization for PJ [0.63573487 0.60691643 0.62420749 0.63688761 0.62074928]\n",
      "TFIDF\n",
      "TFIDF for IE [0.7740634  0.77291066 0.75677233 0.77752161 0.77060519]\n",
      "TFIDF for NS [0.86801153 0.85475504 0.86916427 0.85994236 0.85821326]\n",
      "TFIDF for FT [0.71700288 0.71642651 0.72103746 0.71873199 0.7314121 ]\n",
      "TFIDF for PJ [0.63861671 0.60691643 0.61786744 0.63804035 0.61902017]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1) #n_jobs=-1 allow us to create trees in parallel\n",
    "k_Fold = KFold(n_splits=5)\n",
    "\n",
    "#additonal_Features = ['No_Characters', 'No_Words', 'No_Char-Capital', 'No_Words-Capital', 'No_Punctuations', 'No_WordsInQuotes', 'No_Sentences', 'No_UniqueWords', 'No_Stopwords', 'Avg_WordLength', 'Avg_SentLength', 'UniqueWrd_vs_NoWrd', 'Stopwords_vs_NoWrd','Sentiment_Score']\n",
    "vectorizer_List = {'Count Vectorization' : full_Lem_CV, 'N-gram Vectorizing' : full_Lem_Ngram, 'TFIDF' : full_Lem_tfidf}\n",
    "\n",
    "for title, vect in vectorizer_List.items():\n",
    "    if title == 'N-gram Vectorizing': #Ignore N-gram Vectorizing for now(low memory)\n",
    "        continue\n",
    "    #X_Features = pd.concat( [mbti_FE[additonal_Features], pd.DataFrame(vect)], axis=1)\n",
    "    #print(title)\n",
    "    X_Features = pd.DataFrame(vect.toarray())\n",
    "    print(title + ' for IE', cross_val_score(rf, vect, mbti_Dataset['IE'], cv=k_Fold, scoring='accuracy', n_jobs=-1))\n",
    "    print(title + ' for NS', cross_val_score(rf, vect, mbti_Dataset['NS'], cv=k_Fold, scoring='accuracy', n_jobs=-1))\n",
    "    print(title + ' for FT', cross_val_score(rf, vect, mbti_Dataset['FT'], cv=k_Fold, scoring='accuracy', n_jobs=-1))\n",
    "    print(title + ' for PJ', cross_val_score(rf, vect, mbti_Dataset['PJ'], cv=k_Fold, scoring='accuracy', n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: 0.763 / Recall: 1.0 / Accuracy: 0.763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "X_Features = full_Lem_CV.toarray()\n",
    "X_Features = pd.DataFrame(X_Features)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_Features, mbti_Dataset['IE'], test_size=0.2) # 20% of our dataset is test set\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=20 ,n_jobs=-1)#Max depth of tree is 20\n",
    "rf_model = rf.fit(X_train, Y_train)\n",
    "#sorted(zip(rf_model.feature_importances_, X_train.columns), reverse=True)[0:10] #List top 10 feature importances\n",
    "\n",
    "Y_pred = rf_model.predict(X_test)\n",
    "precision, recall, fscore, support = score(Y_test, Y_pred, pos_label='I', average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), \n",
    "                                                        round(recall, 3), \n",
    "                                                        round((Y_pred==Y_test).sum() / len(Y_pred),3)))\n"
   ]
  }
 ]
}