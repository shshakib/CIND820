{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "6bd3622f6f3f8bb6e8b4643a72dc4bf7a75a1467dea0f2ef918aabb1c737dfb1"
   }
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Setep 5: Machine Learning Model\n",
    "\n",
    "<br>\n",
    "Clean up any values left from any previous steps"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick clean up\n",
    "for name in dir():\n",
    "    if not name.startswith('_'): # and name not in ['mbti_FE','mbti_Dataset', 'full_Lem_CV', 'full_Lem_Ngram', 'full_Lem_tfidf']:\n",
    "        del globals()[name]"
   ]
  },
  {
   "source": [
    "Load Dataset and results from previous steps."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load information from prevous steps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "mbti_Dataset = pd.read_csv('mbti_Dataset.csv')\n",
    "#mbti_FE = pd.read_csv('mbti_FE.csv')\n",
    "\n",
    "#full_Lem_CV = sparse.load_npz('full_Lem_CV.npz')\n",
    "#full_Lem_Ngram = sparse.load_npz('full_Lem_Ngram.npz')\n",
    "#full_Lem_tfidf = sparse.load_npz('full_Lem_tfidf.npz')\n",
    "features_Dic = {'Count Vectorizer': sparse.load_npz('full_Lem_CV.npz'), \n",
    "                'TFIDF Vectorizer': sparse.load_npz('full_Lem_tfidf.npz')}\n",
    "\n",
    "#np.save('full_Lem_CV', full_Lem_CV.toarray())\n",
    "#np.save('f:/full_Lem_Ngram', full_Lem_Ngram.toarray())\n",
    "#np.save('full_Lem_tfidf', full_Lem_tfidf.toarray())"
   ]
  },
  {
   "source": [
    "## 5-1: Random Forest Model\n",
    "### 5-1-1: Explorering Random Forest with Holdout test set + grid-search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Type            Method  Estimators  Max_Depth  Precision    Recall  \\\n",
       "0   Introverts  Count Vectorizer          10       10.0   0.761383  1.000000   \n",
       "1   Introverts  Count Vectorizer          10       20.0   0.768786  0.999249   \n",
       "2   Introverts  Count Vectorizer          10       30.0   0.758242  0.996958   \n",
       "3   Introverts  Count Vectorizer          10        NaN   0.778708  0.978212   \n",
       "4   Introverts  Count Vectorizer          50       10.0   0.764841  1.000000   \n",
       "5   Introverts  Count Vectorizer          50       20.0   0.769452  1.000000   \n",
       "6   Introverts  Count Vectorizer          50       30.0   0.774063  1.000000   \n",
       "7   Introverts  Count Vectorizer          50        NaN   0.774957  1.000000   \n",
       "8   Introverts  Count Vectorizer         100       10.0   0.776945  1.000000   \n",
       "9   Introverts  Count Vectorizer         100       20.0   0.763689  1.000000   \n",
       "10  Introverts  Count Vectorizer         100       30.0   0.761960  1.000000   \n",
       "11  Introverts  Count Vectorizer         100        NaN   0.769497  1.000000   \n",
       "12  Introverts  TFIDF Vectorizer          10       10.0   0.764265  1.000000   \n",
       "13  Introverts  TFIDF Vectorizer          10       20.0   0.792605  0.999272   \n",
       "14  Introverts  TFIDF Vectorizer          10       30.0   0.766377  0.996983   \n",
       "15  Introverts  TFIDF Vectorizer          10        NaN   0.788450  0.962166   \n",
       "16  Introverts  TFIDF Vectorizer          50       10.0   0.763112  1.000000   \n",
       "17  Introverts  TFIDF Vectorizer          50       20.0   0.779700  1.000000   \n",
       "18  Introverts  TFIDF Vectorizer          50       30.0   0.767589  1.000000   \n",
       "19  Introverts  TFIDF Vectorizer          50        NaN   0.770075  0.999250   \n",
       "20  Introverts  TFIDF Vectorizer         100       10.0   0.785591  1.000000   \n",
       "21  Introverts  TFIDF Vectorizer         100       20.0   0.774063  1.000000   \n",
       "22  Introverts  TFIDF Vectorizer         100       30.0   0.779700  1.000000   \n",
       "23  Introverts  TFIDF Vectorizer         100        NaN   0.778996  1.000000   \n",
       "24  Intuitives  Count Vectorizer          10       10.0   0.854755  1.000000   \n",
       "25  Intuitives  Count Vectorizer          10       20.0   0.865130  1.000000   \n",
       "26  Intuitives  Count Vectorizer          10       30.0   0.872622  1.000000   \n",
       "27  Intuitives  Count Vectorizer          10        NaN   0.872549  1.000000   \n",
       "28  Intuitives  Count Vectorizer          50       10.0   0.876657  1.000000   \n",
       "29  Intuitives  Count Vectorizer          50       20.0   0.865130  1.000000   \n",
       "30  Intuitives  Count Vectorizer          50       30.0   0.870893  1.000000   \n",
       "31  Intuitives  Count Vectorizer          50        NaN   0.861015  1.000000   \n",
       "32  Intuitives  Count Vectorizer         100       10.0   0.874928  1.000000   \n",
       "33  Intuitives  Count Vectorizer         100       20.0   0.862248  1.000000   \n",
       "34  Intuitives  Count Vectorizer         100       30.0   0.843228  1.000000   \n",
       "35  Intuitives  Count Vectorizer         100        NaN   0.863977  1.000000   \n",
       "36  Intuitives  TFIDF Vectorizer          10       10.0   0.861095  1.000000   \n",
       "37  Intuitives  TFIDF Vectorizer          10       20.0   0.873775  1.000000   \n",
       "38  Intuitives  TFIDF Vectorizer          10       30.0   0.843228  1.000000   \n",
       "39  Intuitives  TFIDF Vectorizer          10        NaN   0.854755  1.000000   \n",
       "40  Intuitives  TFIDF Vectorizer          50       10.0   0.857061  1.000000   \n",
       "41  Intuitives  TFIDF Vectorizer          50       20.0   0.857061  1.000000   \n",
       "42  Intuitives  TFIDF Vectorizer          50       30.0   0.850720  1.000000   \n",
       "43  Intuitives  TFIDF Vectorizer          50        NaN   0.857637  1.000000   \n",
       "44  Intuitives  TFIDF Vectorizer         100       10.0   0.859366  1.000000   \n",
       "45  Intuitives  TFIDF Vectorizer         100       20.0   0.859942  1.000000   \n",
       "46  Intuitives  TFIDF Vectorizer         100       30.0   0.863977  1.000000   \n",
       "47  Intuitives  TFIDF Vectorizer         100        NaN   0.857637  1.000000   \n",
       "48     Feelers  Count Vectorizer          10       10.0   0.618705  0.823404   \n",
       "49     Feelers  Count Vectorizer          10       20.0   0.610313  0.804905   \n",
       "50     Feelers  Count Vectorizer          10       30.0   0.643446  0.739726   \n",
       "51     Feelers  Count Vectorizer          10        NaN   0.620635  0.839957   \n",
       "52     Feelers  Count Vectorizer          50       10.0   0.643710  0.935649   \n",
       "53     Feelers  Count Vectorizer          50       20.0   0.635659  0.896175   \n",
       "54     Feelers  Count Vectorizer          50       30.0   0.721048  0.871297   \n",
       "55     Feelers  Count Vectorizer          50        NaN   0.654810  0.893054   \n",
       "56     Feelers  Count Vectorizer         100       10.0   0.609157  0.974522   \n",
       "57     Feelers  Count Vectorizer         100       20.0   0.667449  0.921166   \n",
       "58     Feelers  Count Vectorizer         100       30.0   0.661501  0.908175   \n",
       "59     Feelers  Count Vectorizer         100        NaN   0.691237  0.906552   \n",
       "60     Feelers  TFIDF Vectorizer          10       10.0   0.613885  0.844421   \n",
       "61     Feelers  TFIDF Vectorizer          10       20.0   0.670055  0.748967   \n",
       "62     Feelers  TFIDF Vectorizer          10       30.0   0.640107  0.764706   \n",
       "63     Feelers  TFIDF Vectorizer          10        NaN   0.606260  0.786325   \n",
       "64     Feelers  TFIDF Vectorizer          50       10.0   0.601509  0.960570   \n",
       "65     Feelers  TFIDF Vectorizer          50       20.0   0.654574  0.900217   \n",
       "66     Feelers  TFIDF Vectorizer          50       30.0   0.672665  0.859803   \n",
       "67     Feelers  TFIDF Vectorizer          50        NaN   0.650041  0.856681   \n",
       "68     Feelers  TFIDF Vectorizer         100       10.0   0.609459  0.962647   \n",
       "69     Feelers  TFIDF Vectorizer         100       20.0   0.693135  0.884900   \n",
       "70     Feelers  TFIDF Vectorizer         100       30.0   0.705426  0.868505   \n",
       "71     Feelers  TFIDF Vectorizer         100        NaN   0.685477  0.888172   \n",
       "72  Perceivers  Count Vectorizer          10       10.0   0.612233  0.980971   \n",
       "73  Perceivers  Count Vectorizer          10       20.0   0.613166  0.942197   \n",
       "74  Perceivers  Count Vectorizer          10       30.0   0.616000  0.892754   \n",
       "75  Perceivers  Count Vectorizer          10        NaN   0.654947  0.757089   \n",
       "76  Perceivers  Count Vectorizer          50       10.0   0.604035  1.000000   \n",
       "77  Perceivers  Count Vectorizer          50       20.0   0.591329  0.998049   \n",
       "78  Perceivers  Count Vectorizer          50       30.0   0.601299  0.989310   \n",
       "79  Perceivers  Count Vectorizer          50        NaN   0.644795  0.958724   \n",
       "80  Perceivers  Count Vectorizer         100       10.0   0.614986  1.000000   \n",
       "81  Perceivers  Count Vectorizer         100       20.0   0.607287  0.999049   \n",
       "82  Perceivers  Count Vectorizer         100       30.0   0.620268  0.997191   \n",
       "83  Perceivers  Count Vectorizer         100        NaN   0.621266  0.982059   \n",
       "84  Perceivers  TFIDF Vectorizer          10       10.0   0.620201  0.980392   \n",
       "85  Perceivers  TFIDF Vectorizer          10       20.0   0.625241  0.915174   \n",
       "86  Perceivers  TFIDF Vectorizer          10       30.0   0.633588  0.866224   \n",
       "87  Perceivers  TFIDF Vectorizer          10        NaN   0.642105  0.692526   \n",
       "88  Perceivers  TFIDF Vectorizer          50       10.0   0.604732  1.000000   \n",
       "89  Perceivers  TFIDF Vectorizer          50       20.0   0.601166  0.994214   \n",
       "90  Perceivers  TFIDF Vectorizer          50       30.0   0.628419  0.991557   \n",
       "91  Perceivers  TFIDF Vectorizer          50        NaN   0.638407  0.931584   \n",
       "92  Perceivers  TFIDF Vectorizer         100       10.0   0.621902  1.000000   \n",
       "93  Perceivers  TFIDF Vectorizer         100       20.0   0.617919  0.998133   \n",
       "94  Perceivers  TFIDF Vectorizer         100       30.0   0.606872  0.998084   \n",
       "95  Perceivers  TFIDF Vectorizer         100        NaN   0.628872  0.972222   \n",
       "\n",
       "    Accuracy  \n",
       "0      0.761  \n",
       "1      0.769  \n",
       "2      0.757  \n",
       "3      0.770  \n",
       "4      0.765  \n",
       "5      0.769  \n",
       "6      0.774  \n",
       "7      0.775  \n",
       "8      0.777  \n",
       "9      0.764  \n",
       "10     0.762  \n",
       "11     0.770  \n",
       "12     0.764  \n",
       "13     0.793  \n",
       "14     0.765  \n",
       "15     0.770  \n",
       "16     0.763  \n",
       "17     0.780  \n",
       "18     0.768  \n",
       "19     0.770  \n",
       "20     0.786  \n",
       "21     0.774  \n",
       "22     0.780  \n",
       "23     0.779  \n",
       "24     0.855  \n",
       "25     0.865  \n",
       "26     0.873  \n",
       "27     0.873  \n",
       "28     0.877  \n",
       "29     0.865  \n",
       "30     0.871  \n",
       "31     0.861  \n",
       "32     0.875  \n",
       "33     0.862  \n",
       "34     0.843  \n",
       "35     0.864  \n",
       "36     0.861  \n",
       "37     0.874  \n",
       "38     0.843  \n",
       "39     0.855  \n",
       "40     0.857  \n",
       "41     0.857  \n",
       "42     0.851  \n",
       "43     0.858  \n",
       "44     0.859  \n",
       "45     0.860  \n",
       "46     0.864  \n",
       "47     0.858  \n",
       "48     0.629  \n",
       "49     0.633  \n",
       "50     0.633  \n",
       "51     0.639  \n",
       "52     0.671  \n",
       "53     0.674  \n",
       "54     0.737  \n",
       "55     0.698  \n",
       "56     0.647  \n",
       "57     0.713  \n",
       "58     0.714  \n",
       "59     0.733  \n",
       "60     0.631  \n",
       "61     0.654  \n",
       "62     0.641  \n",
       "63     0.609  \n",
       "64     0.644  \n",
       "65     0.695  \n",
       "66     0.706  \n",
       "67     0.677  \n",
       "68     0.647  \n",
       "69     0.723  \n",
       "70     0.731  \n",
       "71     0.722  \n",
       "72     0.612  \n",
       "73     0.610  \n",
       "74     0.604  \n",
       "75     0.609  \n",
       "76     0.604  \n",
       "77     0.591  \n",
       "78     0.605  \n",
       "79     0.650  \n",
       "80     0.615  \n",
       "81     0.608  \n",
       "82     0.622  \n",
       "83     0.624  \n",
       "84     0.617  \n",
       "85     0.613  \n",
       "86     0.614  \n",
       "87     0.578  \n",
       "88     0.605  \n",
       "89     0.602  \n",
       "90     0.635  \n",
       "91     0.633  \n",
       "92     0.622  \n",
       "93     0.618  \n",
       "94     0.610  \n",
       "95     0.638  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Method</th>\n      <th>Estimators</th>\n      <th>Max_Depth</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>10.0</td>\n      <td>0.761383</td>\n      <td>1.000000</td>\n      <td>0.761</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>20.0</td>\n      <td>0.768786</td>\n      <td>0.999249</td>\n      <td>0.769</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>30.0</td>\n      <td>0.758242</td>\n      <td>0.996958</td>\n      <td>0.757</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.778708</td>\n      <td>0.978212</td>\n      <td>0.770</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>10.0</td>\n      <td>0.764841</td>\n      <td>1.000000</td>\n      <td>0.765</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>0.769452</td>\n      <td>1.000000</td>\n      <td>0.769</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>30.0</td>\n      <td>0.774063</td>\n      <td>1.000000</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>0.774957</td>\n      <td>1.000000</td>\n      <td>0.775</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>0.776945</td>\n      <td>1.000000</td>\n      <td>0.777</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>20.0</td>\n      <td>0.763689</td>\n      <td>1.000000</td>\n      <td>0.764</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>30.0</td>\n      <td>0.761960</td>\n      <td>1.000000</td>\n      <td>0.762</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>NaN</td>\n      <td>0.769497</td>\n      <td>1.000000</td>\n      <td>0.770</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>10.0</td>\n      <td>0.764265</td>\n      <td>1.000000</td>\n      <td>0.764</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>20.0</td>\n      <td>0.792605</td>\n      <td>0.999272</td>\n      <td>0.793</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>30.0</td>\n      <td>0.766377</td>\n      <td>0.996983</td>\n      <td>0.765</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.788450</td>\n      <td>0.962166</td>\n      <td>0.770</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>10.0</td>\n      <td>0.763112</td>\n      <td>1.000000</td>\n      <td>0.763</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>0.779700</td>\n      <td>1.000000</td>\n      <td>0.780</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>30.0</td>\n      <td>0.767589</td>\n      <td>1.000000</td>\n      <td>0.768</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>0.770075</td>\n      <td>0.999250</td>\n      <td>0.770</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>0.785591</td>\n      <td>1.000000</td>\n      <td>0.786</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>20.0</td>\n      <td>0.774063</td>\n      <td>1.000000</td>\n      <td>0.774</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>30.0</td>\n      <td>0.779700</td>\n      <td>1.000000</td>\n      <td>0.780</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Introverts</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>NaN</td>\n      <td>0.778996</td>\n      <td>1.000000</td>\n      <td>0.779</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>10.0</td>\n      <td>0.854755</td>\n      <td>1.000000</td>\n      <td>0.855</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>20.0</td>\n      <td>0.865130</td>\n      <td>1.000000</td>\n      <td>0.865</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>30.0</td>\n      <td>0.872622</td>\n      <td>1.000000</td>\n      <td>0.873</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.872549</td>\n      <td>1.000000</td>\n      <td>0.873</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>10.0</td>\n      <td>0.876657</td>\n      <td>1.000000</td>\n      <td>0.877</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>0.865130</td>\n      <td>1.000000</td>\n      <td>0.865</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>30.0</td>\n      <td>0.870893</td>\n      <td>1.000000</td>\n      <td>0.871</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>0.861015</td>\n      <td>1.000000</td>\n      <td>0.861</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>0.874928</td>\n      <td>1.000000</td>\n      <td>0.875</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>20.0</td>\n      <td>0.862248</td>\n      <td>1.000000</td>\n      <td>0.862</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>30.0</td>\n      <td>0.843228</td>\n      <td>1.000000</td>\n      <td>0.843</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Intuitives</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>NaN</td>\n      <td>0.863977</td>\n      <td>1.000000</td>\n      <td>0.864</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>10.0</td>\n      <td>0.861095</td>\n      <td>1.000000</td>\n      <td>0.861</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>20.0</td>\n      <td>0.873775</td>\n      <td>1.000000</td>\n      <td>0.874</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>30.0</td>\n      <td>0.843228</td>\n      <td>1.000000</td>\n      <td>0.843</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.854755</td>\n      <td>1.000000</td>\n      <td>0.855</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>10.0</td>\n      <td>0.857061</td>\n      <td>1.000000</td>\n      <td>0.857</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>0.857061</td>\n      <td>1.000000</td>\n      <td>0.857</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>30.0</td>\n      <td>0.850720</td>\n      <td>1.000000</td>\n      <td>0.851</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>0.857637</td>\n      <td>1.000000</td>\n      <td>0.858</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>0.859366</td>\n      <td>1.000000</td>\n      <td>0.859</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>20.0</td>\n      <td>0.859942</td>\n      <td>1.000000</td>\n      <td>0.860</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>30.0</td>\n      <td>0.863977</td>\n      <td>1.000000</td>\n      <td>0.864</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Intuitives</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>NaN</td>\n      <td>0.857637</td>\n      <td>1.000000</td>\n      <td>0.858</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>10.0</td>\n      <td>0.618705</td>\n      <td>0.823404</td>\n      <td>0.629</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>20.0</td>\n      <td>0.610313</td>\n      <td>0.804905</td>\n      <td>0.633</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>30.0</td>\n      <td>0.643446</td>\n      <td>0.739726</td>\n      <td>0.633</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.620635</td>\n      <td>0.839957</td>\n      <td>0.639</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>10.0</td>\n      <td>0.643710</td>\n      <td>0.935649</td>\n      <td>0.671</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>0.635659</td>\n      <td>0.896175</td>\n      <td>0.674</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>30.0</td>\n      <td>0.721048</td>\n      <td>0.871297</td>\n      <td>0.737</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>0.654810</td>\n      <td>0.893054</td>\n      <td>0.698</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>0.609157</td>\n      <td>0.974522</td>\n      <td>0.647</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>20.0</td>\n      <td>0.667449</td>\n      <td>0.921166</td>\n      <td>0.713</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>30.0</td>\n      <td>0.661501</td>\n      <td>0.908175</td>\n      <td>0.714</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>Feelers</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>NaN</td>\n      <td>0.691237</td>\n      <td>0.906552</td>\n      <td>0.733</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>10.0</td>\n      <td>0.613885</td>\n      <td>0.844421</td>\n      <td>0.631</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>20.0</td>\n      <td>0.670055</td>\n      <td>0.748967</td>\n      <td>0.654</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>30.0</td>\n      <td>0.640107</td>\n      <td>0.764706</td>\n      <td>0.641</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.606260</td>\n      <td>0.786325</td>\n      <td>0.609</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>10.0</td>\n      <td>0.601509</td>\n      <td>0.960570</td>\n      <td>0.644</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>0.654574</td>\n      <td>0.900217</td>\n      <td>0.695</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>30.0</td>\n      <td>0.672665</td>\n      <td>0.859803</td>\n      <td>0.706</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>0.650041</td>\n      <td>0.856681</td>\n      <td>0.677</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>0.609459</td>\n      <td>0.962647</td>\n      <td>0.647</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>20.0</td>\n      <td>0.693135</td>\n      <td>0.884900</td>\n      <td>0.723</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>30.0</td>\n      <td>0.705426</td>\n      <td>0.868505</td>\n      <td>0.731</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>Feelers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>NaN</td>\n      <td>0.685477</td>\n      <td>0.888172</td>\n      <td>0.722</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>10.0</td>\n      <td>0.612233</td>\n      <td>0.980971</td>\n      <td>0.612</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>20.0</td>\n      <td>0.613166</td>\n      <td>0.942197</td>\n      <td>0.610</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>30.0</td>\n      <td>0.616000</td>\n      <td>0.892754</td>\n      <td>0.604</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.654947</td>\n      <td>0.757089</td>\n      <td>0.609</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>10.0</td>\n      <td>0.604035</td>\n      <td>1.000000</td>\n      <td>0.604</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>0.591329</td>\n      <td>0.998049</td>\n      <td>0.591</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>30.0</td>\n      <td>0.601299</td>\n      <td>0.989310</td>\n      <td>0.605</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>0.644795</td>\n      <td>0.958724</td>\n      <td>0.650</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>0.614986</td>\n      <td>1.000000</td>\n      <td>0.615</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>20.0</td>\n      <td>0.607287</td>\n      <td>0.999049</td>\n      <td>0.608</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>30.0</td>\n      <td>0.620268</td>\n      <td>0.997191</td>\n      <td>0.622</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>Perceivers</td>\n      <td>Count Vectorizer</td>\n      <td>100</td>\n      <td>NaN</td>\n      <td>0.621266</td>\n      <td>0.982059</td>\n      <td>0.624</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>10.0</td>\n      <td>0.620201</td>\n      <td>0.980392</td>\n      <td>0.617</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>20.0</td>\n      <td>0.625241</td>\n      <td>0.915174</td>\n      <td>0.613</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>30.0</td>\n      <td>0.633588</td>\n      <td>0.866224</td>\n      <td>0.614</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.642105</td>\n      <td>0.692526</td>\n      <td>0.578</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>10.0</td>\n      <td>0.604732</td>\n      <td>1.000000</td>\n      <td>0.605</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>0.601166</td>\n      <td>0.994214</td>\n      <td>0.602</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>30.0</td>\n      <td>0.628419</td>\n      <td>0.991557</td>\n      <td>0.635</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>0.638407</td>\n      <td>0.931584</td>\n      <td>0.633</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>10.0</td>\n      <td>0.621902</td>\n      <td>1.000000</td>\n      <td>0.622</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>20.0</td>\n      <td>0.617919</td>\n      <td>0.998133</td>\n      <td>0.618</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>30.0</td>\n      <td>0.606872</td>\n      <td>0.998084</td>\n      <td>0.610</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Perceivers</td>\n      <td>TFIDF Vectorizer</td>\n      <td>100</td>\n      <td>NaN</td>\n      <td>0.628872</td>\n      <td>0.972222</td>\n      <td>0.638</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_rows', None, 'display.max_colwidth', 500)\n",
    "\n",
    "def rfClassifier_GridSearch(X_Features, dataset_PD, test_Szie, Lable, feature_type, n_est, depth, is_print = True,):\n",
    "    if Lable == 'IE':\n",
    "        Lable = 'I'\n",
    "        predict_Lable = 'Introverts'\n",
    "    elif Lable == 'NS':\n",
    "        Lable = 'N'\n",
    "        predict_Lable = 'Intuitives'\n",
    "    elif Lable == 'FT':\n",
    "        Lable = 'F'\n",
    "        predict_Lable = 'Feelers'\n",
    "    elif Lable == 'PJ':\n",
    "        Lable = 'P'\n",
    "        predict_Lable = 'Perceivers'\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_Features, dataset_PD, test_size=test_Szie)#20% of dataset is test set\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, max_depth=depth ,n_jobs=-1)#Max depth of tree is 20\n",
    "    rf_model = rf.fit(X_train, Y_train)\n",
    "    Y_pred = rf_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(Y_test, Y_pred, pos_label=Lable, average='binary')\n",
    "    if is_print:\n",
    "        print('Being ' + predict_Lable + ' using ' + feature_type + ':'  ,\n",
    "        'Estimators: {} / Max_Depth: {} --> Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "                                                        n_est,\n",
    "                                                        depth,\n",
    "                                                        round(precision, 3),\n",
    "                                                        round(recall, 3), \n",
    "                                                        round((Y_pred==Y_test).sum() / len(Y_pred),3)))\n",
    "    return([predict_Lable, feature_type, n_est, depth, precision, recall, round((Y_pred==Y_test).sum() / len(Y_pred),3)])\n",
    "\n",
    "\n",
    "\n",
    "classes = ['IE' , 'NS', 'FT', 'PJ']\n",
    "rf_result = []\n",
    "\n",
    "for item in classes:\n",
    "    for key, X_Features in features_Dic.items():\n",
    "        for n_est in [10, 50, 100]:\n",
    "            for depth in [10, 20, 30, None]:\n",
    "                rf_result.append(rfClassifier_GridSearch(X_Features, mbti_Dataset[item], 0.2, item, key, n_est, depth, is_print=False))\n",
    "\n",
    "pd.DataFrame(rf_result, columns= ['Type', 'Method', 'Estimators', 'Max_Depth', 'Precision', 'Recall', 'Accuracy']).to_csv('RF_Holdout_Result.csv')\n",
    "pd.DataFrame(rf_result, columns= ['Type', 'Method', 'Estimators', 'Max_Depth', 'Precision', 'Recall', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### 5-1-2: Evaluation Random Forest Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   param_max_depth param_n_estimators  std_test_score  mean_test_score  \\\n",
      "6               90                 10        0.004380         0.771873   \n",
      "0               30                 10        0.001094         0.770605   \n",
      "10            None                150        0.000565         0.770490   \n",
      "11            None                300        0.000461         0.770375   \n",
      "7               90                150        0.000461         0.770259   \n",
      "\n",
      "    rank_test_score  \n",
      "6                 1  \n",
      "0                 2  \n",
      "10                3  \n",
      "11                4  \n",
      "7                 5  \n",
      "Count Vectorizer\n",
      "   param_max_depth param_n_estimators  std_test_score  mean_test_score  \\\n",
      "10            None                150        0.000936         0.770259   \n",
      "8               90                300        0.000431         0.770144   \n",
      "11            None                300        0.000672         0.770144   \n",
      "4               60                150        0.000365         0.770029   \n",
      "5               60                300        0.000365         0.770029   \n",
      "\n",
      "    rank_test_score  \n",
      "10                1  \n",
      "8                 2  \n",
      "11                2  \n",
      "4                 4  \n",
      "5                 4  \n",
      "TFIDF Vectorizer\n",
      "  param_max_depth param_n_estimators  std_test_score  mean_test_score  \\\n",
      "6              90                 10        0.001314         0.862824   \n",
      "3              60                 10        0.000365         0.862248   \n",
      "0              30                 10        0.000282         0.862017   \n",
      "1              30                150        0.000282         0.862017   \n",
      "2              30                300        0.000282         0.862017   \n",
      "\n",
      "   rank_test_score  \n",
      "6                1  \n",
      "3                2  \n",
      "0                3  \n",
      "1                3  \n",
      "2                3  \n",
      "Count Vectorizer\n",
      "  param_max_depth param_n_estimators  std_test_score  mean_test_score  \\\n",
      "3              60                 10        0.000863         0.862478   \n",
      "9            None                 10        0.000565         0.862363   \n",
      "1              30                150        0.000282         0.862017   \n",
      "2              30                300        0.000282         0.862017   \n",
      "4              60                150        0.000282         0.862017   \n",
      "\n",
      "   rank_test_score  \n",
      "3                1  \n",
      "9                2  \n",
      "1                3  \n",
      "2                3  \n",
      "4                3  \n",
      "TFIDF Vectorizer\n",
      "   param_max_depth param_n_estimators  std_test_score  mean_test_score  \\\n",
      "5               60                300        0.005996         0.747896   \n",
      "8               90                300        0.007018         0.747896   \n",
      "11            None                300        0.008243         0.747666   \n",
      "7               90                150        0.006341         0.743862   \n",
      "2               30                300        0.005828         0.743170   \n",
      "\n",
      "    rank_test_score  \n",
      "5                 1  \n",
      "8                 1  \n",
      "11                3  \n",
      "7                 4  \n",
      "2                 5  \n",
      "Count Vectorizer\n",
      "   param_max_depth param_n_estimators  std_test_score  mean_test_score  \\\n",
      "8               90                300        0.008031         0.747666   \n",
      "11            None                300        0.014520         0.745591   \n",
      "5               60                300        0.007203         0.744553   \n",
      "4               60                150        0.010211         0.739712   \n",
      "2               30                300        0.007453         0.737752   \n",
      "\n",
      "    rank_test_score  \n",
      "8                 1  \n",
      "11                2  \n",
      "5                 3  \n",
      "4                 4  \n",
      "2                 5  \n",
      "TFIDF Vectorizer\n",
      "   param_max_depth param_n_estimators  std_test_score  mean_test_score  \\\n",
      "10            None                150        0.004739         0.621902   \n",
      "7               90                150        0.002323         0.618790   \n",
      "4               60                150        0.002536         0.617983   \n",
      "11            None                300        0.003102         0.617406   \n",
      "8               90                300        0.002856         0.616830   \n",
      "\n",
      "    rank_test_score  \n",
      "10                1  \n",
      "7                 2  \n",
      "4                 3  \n",
      "11                4  \n",
      "8                 5  \n",
      "Count Vectorizer\n",
      "   param_max_depth param_n_estimators  std_test_score  mean_test_score  \\\n",
      "10            None                150        0.003470         0.626282   \n",
      "7               90                150        0.003019         0.622709   \n",
      "4               60                150        0.003059         0.619481   \n",
      "8               90                300        0.002713         0.618329   \n",
      "11            None                300        0.004488         0.617061   \n",
      "\n",
      "    rank_test_score  \n",
      "10                1  \n",
      "7                 2  \n",
      "4                 3  \n",
      "8                 4  \n",
      "11                5  \n",
      "TFIDF Vectorizer\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "def RF_Evaluation(param, X_Features, dataset_PD, lable, is_print = True):\n",
    "    rf = RandomForestClassifier()\n",
    "    gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)#cv=5 means 5 folde validation\n",
    "    gs_fit = gs.fit(X_Features, dataset_PD)\n",
    "    if is_print:\n",
    "        print(pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[['param_max_depth',\n",
    "        'param_n_estimators', 'std_test_score', 'mean_test_score', 'rank_test_score']][0:5])\n",
    "\n",
    "    return(pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[['param_max_depth',\n",
    "    'param_n_estimators', 'std_test_score', 'mean_test_score', 'rank_test_score']][0:5])\n",
    "\n",
    "\n",
    "param = {'n_estimators' : [10, 150, 300],\n",
    "        'max_depth' : [30, 60, 90, None]}\n",
    "\n",
    "classes = ['IE' , 'NS', 'FT', 'PJ']\n",
    "for item in classes:\n",
    "    for key, X_Features in features_Dic.items():\n",
    "        RF_Evaluation(param, X_Features, mbti_Dataset[item], item)\n",
    "        print(key)\n"
   ]
  },
  {
   "source": [
    "## 5-2: Gradient Boosting Model\n",
    "### 5-2-1: Gradient Boosting with Holdout test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ving to 0.1 as Learning_Rate at:  2021-06-26 02:08:21.947917\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 02:20:05.114699\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 02:20:05.114699\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 02:48:08.762527\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 03:05:06.819204\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 03:20:12.301838\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 03:20:12.301838\n",
      "Moving to 150 estimators at:  2021-06-26 03:20:12.301838\n",
      "Moving to TFIDF Vectorizer feature at:  2021-06-26 03:20:12.301838\n",
      "Moving to IE class at:  2021-06-26 03:20:12.301838\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 03:21:31.333904\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 03:22:50.244996\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 03:24:07.262245\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 03:24:07.262245\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 03:26:22.749736\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 03:28:23.732490\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 03:30:00.448052\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 03:30:00.449047\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 03:33:50.473853\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 03:36:45.758365\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 03:38:45.028588\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 03:38:45.028588\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 03:43:50.305800\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 03:47:28.233304\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 03:49:52.332168\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 03:49:52.333165\n",
      "Moving to 50 estimators at:  2021-06-26 03:49:52.333165\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 03:52:29.804288\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 03:55:05.924021\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 03:57:37.383137\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 03:57:37.384134\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 04:02:20.300061\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 04:06:01.956740\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 04:09:12.953989\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 04:09:12.953989\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 04:17:33.697503\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 04:22:33.868668\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 04:26:38.636354\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 04:26:38.636354\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 04:37:05.623742\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 04:42:59.283777\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 04:47:48.993699\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 04:47:48.994696\n",
      "Moving to 100 estimators at:  2021-06-26 04:47:48.994696\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 04:51:46.302980\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 04:55:39.100799\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 04:59:26.428853\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 04:59:26.429850\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 05:06:25.558375\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 05:11:43.282029\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 05:16:31.109808\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 05:16:31.109808\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 05:28:15.112238\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 05:35:09.545842\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 05:41:02.050075\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 05:41:02.051073\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 05:55:46.444325\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 06:03:57.122724\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 06:10:56.815422\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 06:10:56.815422\n",
      "Moving to 150 estimators at:  2021-06-26 06:10:56.815422\n",
      "Moving to Count Vectorizer feature at:  2021-06-26 06:10:56.815422\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 06:12:44.753933\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 06:14:33.434765\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 06:16:20.470688\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 06:16:20.471685\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 06:19:42.298257\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 06:22:48.668038\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 06:25:35.987185\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 06:25:35.987185\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 06:30:51.988379\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 06:35:23.756177\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 06:39:17.778804\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 06:39:17.778804\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 06:45:59.184184\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 06:51:59.206050\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 06:56:54.534003\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 06:56:54.534003\n",
      "Moving to 50 estimators at:  2021-06-26 06:56:54.534003\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 07:00:28.828878\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 07:04:02.816953\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 07:07:35.201468\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 07:07:35.201468\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 07:14:11.320493\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 07:20:07.725923\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 07:25:42.267529\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 07:25:42.267529\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 07:36:50.016381\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 07:45:18.671032\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 07:53:01.647994\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 07:53:01.647994\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 08:07:46.845168\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 08:18:38.871270\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 08:28:27.889842\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 08:28:27.889842\n",
      "Moving to 100 estimators at:  2021-06-26 08:28:27.889842\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 08:33:48.644792\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 08:39:06.792302\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 08:44:26.579921\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 08:44:26.579921\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 08:54:32.880309\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 09:03:17.019448\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 09:11:38.758482\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 09:11:38.758482\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 09:28:05.605551\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 09:40:17.836248\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 09:51:46.259296\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 09:51:46.259296\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 10:13:10.751827\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 10:29:08.162157\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 10:43:49.311148\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 10:43:49.312144\n",
      "Moving to 150 estimators at:  2021-06-26 10:43:49.312144\n",
      "Moving to TFIDF Vectorizer feature at:  2021-06-26 10:43:49.312144\n",
      "Moving to NS class at:  2021-06-26 10:43:49.312144\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 10:45:13.017483\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 10:46:34.611404\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 10:47:53.508533\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 10:47:53.508533\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 10:51:07.544511\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 10:53:55.885991\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 10:55:46.192171\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 10:55:46.193168\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 11:03:02.007443\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 11:09:04.732219\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 11:11:34.099802\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 11:11:34.099802\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 11:23:31.529986\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 11:34:03.985796\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 11:37:30.986138\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 11:37:30.987136\n",
      "Moving to 50 estimators at:  2021-06-26 11:37:30.988135\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 11:40:20.602588\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 11:43:04.268552\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 11:45:42.799965\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 11:45:42.799965\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 11:52:20.726181\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 11:57:49.917979\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 12:01:31.526928\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 12:01:31.527924\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 12:17:10.118650\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 12:27:23.539293\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 12:31:59.824135\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 12:31:59.824135\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 12:55:02.410142\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 13:12:26.170247\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 13:18:30.793881\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 13:18:30.793881\n",
      "Moving to 100 estimators at:  2021-06-26 13:18:30.793881\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 13:22:37.676464\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 13:26:38.513820\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 13:30:30.238705\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 13:30:30.239703\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 13:39:43.785310\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 13:46:54.495229\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 13:52:05.521196\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 13:52:05.521196\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 14:14:44.313223\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 14:29:06.063304\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 14:35:50.794429\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 14:35:50.794429\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 15:12:52.510261\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 15:39:00.562661\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 15:47:57.792875\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 15:47:57.792875\n",
      "Moving to 150 estimators at:  2021-06-26 15:47:57.792875\n",
      "Moving to Count Vectorizer feature at:  2021-06-26 15:47:57.792875\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 15:49:48.586018\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 15:51:38.150429\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 15:53:25.730187\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 15:53:25.731183\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 15:57:39.245845\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 16:01:24.689488\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 16:04:23.528753\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 16:04:23.528753\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 16:12:33.368935\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 16:19:57.646448\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 16:24:16.319366\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 16:24:16.319366\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 16:36:27.087407\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 16:48:49.776410\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 16:54:34.120899\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 16:54:34.120899\n",
      "Moving to 50 estimators at:  2021-06-26 16:54:34.120899\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 16:58:16.150656\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 17:01:52.453033\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 17:05:26.007262\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 17:05:26.007262\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 17:13:41.325934\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 17:20:53.998576\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 17:26:44.930842\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 17:26:44.930842\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 17:44:00.197233\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 17:57:08.187088\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 18:05:25.453441\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 18:05:25.453441\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 18:32:45.743299\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 18:53:40.471624\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 19:04:49.956411\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 19:04:49.957407\n",
      "Moving to 100 estimators at:  2021-06-26 19:04:49.957407\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 19:10:19.810039\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 19:15:45.275080\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 19:21:04.102939\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 19:21:04.102939\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 19:33:07.388788\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 19:43:13.794858\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 19:51:54.650030\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 19:51:54.651027\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 20:17:58.341014\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 20:36:36.448921\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 20:49:04.176330\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 20:49:04.176330\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 21:30:24.394077\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 22:03:42.117592\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 22:20:11.184244\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 22:20:11.184244\n",
      "Moving to 150 estimators at:  2021-06-26 22:20:11.184244\n",
      "Moving to TFIDF Vectorizer feature at:  2021-06-26 22:20:11.184244\n",
      "Moving to FT class at:  2021-06-26 22:20:11.184244\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 22:21:32.105765\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 22:22:52.287583\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 22:24:10.061423\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 22:24:10.061423\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 22:27:09.219417\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 22:29:37.102510\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 22:31:24.894097\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 22:31:24.895093\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 22:37:58.884227\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 22:42:39.174857\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 22:44:53.969790\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 22:44:53.970786\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 22:53:39.614462\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 23:00:44.904535\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 23:03:36.288325\n",
      "Moving to 15 as Max_Depth at:  2021-06-26 23:03:36.288325\n",
      "Moving to 50 estimators at:  2021-06-26 23:03:36.288325\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 23:06:17.303402\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 23:08:55.395379\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 23:11:30.062826\n",
      "Moving to 3 as Max_Depth at:  2021-06-26 23:11:30.062826\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 23:17:28.994752\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 23:21:54.574055\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 23:25:19.858977\n",
      "Moving to 7 as Max_Depth at:  2021-06-26 23:25:19.859974\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-26 23:38:21.387164\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-26 23:45:30.652096\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-26 23:49:52.017538\n",
      "Moving to 11 as Max_Depth at:  2021-06-26 23:49:52.017538\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 00:09:17.649060\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 00:19:18.851078\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 00:24:47.493756\n",
      "Moving to 15 as Max_Depth at:  2021-06-27 00:24:47.494753\n",
      "Moving to 100 estimators at:  2021-06-27 00:24:47.494753\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 00:28:48.572575\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 00:32:44.595558\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 00:36:36.735110\n",
      "Moving to 3 as Max_Depth at:  2021-06-27 00:36:36.735110\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 00:45:24.912384\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 00:51:35.895832\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 00:56:38.713192\n",
      "Moving to 7 as Max_Depth at:  2021-06-27 00:56:38.713192\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 01:16:16.315010\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 01:26:09.929221\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 01:33:21.430721\n",
      "Moving to 11 as Max_Depth at:  2021-06-27 01:33:21.430721\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 02:09:21.425489\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 02:22:48.952864\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 02:30:49.723039\n",
      "Moving to 15 as Max_Depth at:  2021-06-27 02:30:49.723039\n",
      "Moving to 150 estimators at:  2021-06-27 02:30:49.724039\n",
      "Moving to Count Vectorizer feature at:  2021-06-27 02:30:49.724039\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 02:32:39.360637\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 02:34:27.325125\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 02:36:14.956226\n",
      "Moving to 3 as Max_Depth at:  2021-06-27 02:36:14.957223\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 02:40:10.061837\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 02:43:35.782532\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 02:46:32.618197\n",
      "Moving to 7 as Max_Depth at:  2021-06-27 02:46:32.618197\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 02:53:45.750675\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 02:59:59.008036\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 03:04:06.070567\n",
      "Moving to 11 as Max_Depth at:  2021-06-27 03:04:06.071565\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 03:14:29.730531\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 03:23:25.940862\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 03:28:44.244062\n",
      "Moving to 15 as Max_Depth at:  2021-06-27 03:28:44.244062\n",
      "Moving to 50 estimators at:  2021-06-27 03:28:44.244062\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 03:32:20.642468\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 03:35:57.282337\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 03:39:31.914048\n",
      "Moving to 3 as Max_Depth at:  2021-06-27 03:39:31.915045\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 03:47:26.110710\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 03:53:56.136178\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 03:59:50.802855\n",
      "Moving to 7 as Max_Depth at:  2021-06-27 03:59:50.802855\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 04:15:32.871845\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 04:25:58.432795\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 04:34:19.027493\n",
      "Moving to 11 as Max_Depth at:  2021-06-27 04:34:19.028492\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 04:57:08.104573\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 05:11:56.601331\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 05:22:29.254491\n",
      "Moving to 15 as Max_Depth at:  2021-06-27 05:22:29.254491\n",
      "Moving to 100 estimators at:  2021-06-27 05:22:29.254491\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 05:28:01.005869\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 05:33:28.941562\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 05:38:53.151620\n",
      "Moving to 3 as Max_Depth at:  2021-06-27 05:38:53.151620\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 05:50:29.133430\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 06:00:01.406299\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 06:08:35.587730\n",
      "Moving to 7 as Max_Depth at:  2021-06-27 06:08:35.588728\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 06:32:38.453093\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 06:47:11.646134\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 06:59:20.278071\n",
      "Moving to 11 as Max_Depth at:  2021-06-27 06:59:20.278071\n",
      "Moving to 0.01 as Learning_Rate at:  2021-06-27 07:35:38.691122\n",
      "Moving to 0.1 as Learning_Rate at:  2021-06-27 07:55:51.517885\n",
      "Moving to 1.0 as Learning_Rate at:  2021-06-27 08:11:27.720875\n",
      "Moving to 15 as Max_Depth at:  2021-06-27 08:11:27.720875\n",
      "Moving to 150 estimators at:  2021-06-27 08:11:27.720875\n",
      "Moving to TFIDF Vectorizer feature at:  2021-06-27 08:11:27.720875\n",
      "Moving to PJ class at:  2021-06-27 08:11:27.720875\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Type            Method  Estimators  Max_Depth  Learning_Rate  \\\n",
       "0  Introverts  Count Vectorizer          50          3           0.01   \n",
       "1  Introverts  Count Vectorizer          50          3           0.10   \n",
       "2  Introverts  Count Vectorizer          50          3           1.00   \n",
       "3  Introverts  Count Vectorizer          50          7           0.01   \n",
       "4  Introverts  Count Vectorizer          50          7           0.10   \n",
       "\n",
       "   Precision    Recall  Accuracy  \n",
       "0   0.774640  1.000000     0.775  \n",
       "1   0.828499  0.973333     0.822  \n",
       "2   0.842327  0.891030     0.786  \n",
       "3   0.758083  0.999239     0.758  \n",
       "4   0.821705  0.960725     0.811  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Method</th>\n      <th>Estimators</th>\n      <th>Max_Depth</th>\n      <th>Learning_Rate</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>3</td>\n      <td>0.01</td>\n      <td>0.774640</td>\n      <td>1.000000</td>\n      <td>0.775</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>3</td>\n      <td>0.10</td>\n      <td>0.828499</td>\n      <td>0.973333</td>\n      <td>0.822</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>3</td>\n      <td>1.00</td>\n      <td>0.842327</td>\n      <td>0.891030</td>\n      <td>0.786</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>7</td>\n      <td>0.01</td>\n      <td>0.758083</td>\n      <td>0.999239</td>\n      <td>0.758</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Introverts</td>\n      <td>Count Vectorizer</td>\n      <td>50</td>\n      <td>7</td>\n      <td>0.10</td>\n      <td>0.821705</td>\n      <td>0.960725</td>\n      <td>0.811</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None, 'display.max_colwidth', 500)\n",
    "\n",
    "\n",
    "def GBoosting_GridSearch(X_Features, dataset_PD, test_Szie, Lable, feature_type , n_est, depth, lr ,is_print = True):\n",
    "    if Lable == 'IE':\n",
    "        Lable = 'I'\n",
    "        predict_Lable = 'Introverts'\n",
    "    elif Lable == 'NS':\n",
    "        Lable = 'N'\n",
    "        predict_Lable = 'Intuitives'\n",
    "    elif Lable == 'FT':\n",
    "        Lable = 'F'\n",
    "        predict_Lable = 'Feelers'\n",
    "    elif Lable == 'PJ':\n",
    "        Lable = 'P'\n",
    "        predict_Lable = 'Perceivers'\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_Features, dataset_PD, test_size=test_Szie) # 20% of our dataset is test set\n",
    "    gb = GradientBoostingClassifier(n_estimators=n_est, max_depth=depth , learning_rate=lr)#Max depth of tree is 20\n",
    "    gb_model = gb.fit(X_train, Y_train)\n",
    "    Y_pred = gb_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(Y_test, Y_pred, pos_label=Lable, average='binary')\n",
    "    if is_print:\n",
    "        print('Being ' + predict_Lable + ' using ' + feature_type + ': '  ,'Estimators: {} / Max_Depth: {} / Learning_Rate: {} --> Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "                                                        n_est,\n",
    "                                                        depth,\n",
    "                                                        lr,\n",
    "                                                        round(precision, 3),\n",
    "                                                        round(recall, 3), \n",
    "                                                        round((Y_pred==Y_test).sum() / len(Y_pred),3)))\n",
    "    return([predict_Lable, feature_type, n_est, depth, lr, precision, recall, round((Y_pred==Y_test).sum() / len(Y_pred),3)])\n",
    "\n",
    "\n",
    "\n",
    "classes = ['IE' , 'NS', 'FT', 'PJ']\n",
    "gb_result = []\n",
    "\n",
    "for item in classes:\n",
    "    for key, X_Features in features_Dic.items():\n",
    "        for n_est in [50, 100, 150]:\n",
    "            for depth in [3, 7, 11, 15]:\n",
    "                for lr in [0.01, 0.10, 1.00]:\n",
    "                    gb_result.append(GBoosting_GridSearch(X_Features, mbti_Dataset[item], 0.2, item, key, n_est, depth, lr, is_print=False))\n",
    "                    print('Moving to {} as Learning_Rate at: '.format(lr), datetime.now())\n",
    "                print('Moving to {} as Max_Depth at: '.format(depth), datetime.now())\n",
    "            print('Moving to {} estimators at: '.format(n_est), datetime.now())\n",
    "        print('Moving to {} feature at: '.format(key), datetime.now())\n",
    "    print('Moving to {} class at: '.format(item), datetime.now())\n",
    "\n",
    "pd.DataFrame(gb_result, columns= ['Type', 'Method', 'Estimators', 'Max_Depth', 'Learning_Rate','Precision', 'Recall', 'Accuracy']).to_csv('GB_Holdout_Result.csv')\n",
    "pd.DataFrame(gb_result, columns= ['Type', 'Method', 'Estimators', 'Max_Depth', 'Learning_Rate','Precision', 'Recall', 'Accuracy']).head()\n"
   ]
  },
  {
   "source": [
    "### 5-2-2: Evaluation Gradient Boosting Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "\n",
    "def GB_Evaluation(param, X_Features, dataset_PD, lable):\n",
    "    gb = GradientBoostingClassifier()\n",
    "    gs = GridSearchCV(gb, param, cv=5)#cv=5 meand 5 folde validation\n",
    "    gs_fit = gs.fit(X_Features, dataset_PD)\n",
    "    print(pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[['param_max_depth',\n",
    "     'param_n_estimators', 'std_test_score', 'mean_test_score', 'rank_test_score']][0:5])\n",
    "\n",
    "    return(pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[['param_max_depth',\n",
    "     'param_n_estimators', 'std_test_score', 'mean_test_score', 'rank_test_score']][0:5])\n",
    "  \n",
    "param = {'n_estimators' : [50, 100, 150],\n",
    "                'max_depth' : [7, 11, 15],\n",
    "                'Learning_rate' : [0.1]}\n",
    "\n",
    "classes = ['IE' , 'NS', 'FT', 'PJ']\n",
    "\n",
    "\n",
    "for item in classes:\n",
    "    for key, X_Features in features_Dic.items():\n",
    "        GB_Evaluation(param, X_Features, mbti_Dataset[item], item)\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}