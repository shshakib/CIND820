{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "6bd3622f6f3f8bb6e8b4643a72dc4bf7a75a1467dea0f2ef918aabb1c737dfb1"
   }
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Setep 5: Machine Learning Model\n",
    "\n",
    "<br>\n",
    "Clean up any values left from any previous steps"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick clean up\n",
    "for name in dir():\n",
    "    if not name.startswith('_'): # and name not in ['mbti_FE','mbti_Dataset', 'full_Lem_CV', 'full_Lem_Ngram', 'full_Lem_tfidf']:\n",
    "        del globals()[name]"
   ]
  },
  {
   "source": [
    "Load Dataset and results from previous steps."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'd:\\x0cull_Lem_Ngram.npy'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-8ea27789586c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#np.save('full_Lem_CV', full_Lem_CV.toarray())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd:\\full_Lem_Ngram'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_Lem_Ngram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;31m#np.save('full_Lem_tfidf', full_Lem_tfidf.toarray())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[0mfile_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'd:\\x0cull_Lem_Ngram.npy'"
     ]
    }
   ],
   "source": [
    "#Load information from prevous steps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "#mbti_Dataset = pd.read_csv('mbti_Dataset.csv')\n",
    "#mbti_FE = pd.read_csv('mbti_FE.csv')\n",
    "\n",
    "#full_Lem_CV = sparse.load_npz('full_Lem_CV.npz')\n",
    "full_Lem_Ngram = sparse.load_npz('full_Lem_Ngram.npz')\n",
    "#full_Lem_tfidf = sparse.load_npz('full_Lem_tfidf.npz')\n",
    "\n",
    "\n",
    "#np.save('full_Lem_CV', full_Lem_CV.toarray())\n",
    "np.save('d:\\full_Lem_Ngram', full_Lem_Ngram.toarray())\n",
    "#np.save('full_Lem_tfidf', full_Lem_tfidf.toarray())"
   ]
  },
  {
   "source": [
    "## 5-1: Random Forest Model\n",
    "### 5-1-1: Random Forest with Holdout test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results for predicting beingI Precision: 0.774 / Recall: 1.0 / Accuracy: 0.774\n",
      "Results for predicting beingN Precision: 0.856 / Recall: 1.0 / Accuracy: 0.856\n",
      "Results for predicting beingF Precision: 0.669 / Recall: 0.87 / Accuracy: 0.699\n",
      "Results for predicting beingP Precision: 0.597 / Recall: 0.995 / Accuracy: 0.598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "#additonal_Features = ['No_Characters', 'No_Words', 'No_Char-Capital', 'No_Words-Capital', 'No_Punctuations', 'No_WordsInQuotes', 'No_Sentences', 'No_UniqueWords', 'No_Stopwords', 'Avg_WordLength', 'Avg_SentLength', 'UniqueWrd_vs_NoWrd', 'Stopwords_vs_NoWrd','Sentiment_Score']\n",
    "\n",
    "X_Features = full_Lem_tfidf.toarray()\n",
    "X_Features = pd.DataFrame(X_Features)\n",
    "\n",
    "def rfClassifier_HoldhoutSet(X_Features, dataset_PD, test_Szie, predict_Lable, is_print = True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_Features, dataset_PD, test_size=test_Szie) # 20% of our dataset is test set\n",
    "    rf = RandomForestClassifier(n_estimators=50, max_depth=20 ,n_jobs=-1)#Max depth of tree is 20\n",
    "    rf_model = rf.fit(X_train, Y_train)\n",
    "    #sorted(zip(rf_model.feature_importances_, X_train.columns), reverse=True)[0:10] #List top 10 feature importances\n",
    "    Y_pred = rf_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(Y_test, Y_pred, pos_label=predict_Lable, average='binary')\n",
    "    if is_print:\n",
    "        print('Results for predicting being ' + predict_Lable ,'Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                        round(recall, 3), \n",
    "                                                        round((Y_pred==Y_test).sum() / len(Y_pred),3)))\n",
    "    return([precision, recall, fscore, support])\n",
    "\n",
    "\n",
    "rfClassifier_HoldhoutSet(X_Features, mbti_Dataset['IE'], 0.2, 'I')\n",
    "rfClassifier_HoldhoutSet(X_Features, mbti_Dataset['NS'], 0.2, 'N')\n",
    "rfClassifier_HoldhoutSet(X_Features, mbti_Dataset['FT'], 0.2, 'F')\n",
    "rfClassifier_HoldhoutSet(X_Features, mbti_Dataset['PJ'], 0.2, 'P')"
   ]
  },
  {
   "source": [
    "Explorering our model with grid-search:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results for predicting being I for  Est: 10 / Depth: 10 ----- Precision: 0.762 / Recall: 1.0 / Accuracy: 0.762\n",
      "Results for predicting being N for  Est: 10 / Depth: 10 ----- Precision: 0.858 / Recall: 1.0 / Accuracy: 0.858\n",
      "Results for predicting being F for  Est: 10 / Depth: 10 ----- Precision: 0.606 / Recall: 0.849 / Accuracy: 0.614\n",
      "Results for predicting being P for  Est: 10 / Depth: 10 ----- Precision: 0.605 / Recall: 0.988 / Accuracy: 0.603\n",
      "Results for predicting being I for  Est: 10 / Depth: 20 ----- Precision: 0.774 / Recall: 0.999 / Accuracy: 0.773\n",
      "Results for predicting being N for  Est: 10 / Depth: 20 ----- Precision: 0.876 / Recall: 1.0 / Accuracy: 0.876\n",
      "Results for predicting being F for  Est: 10 / Depth: 20 ----- Precision: 0.614 / Recall: 0.775 / Accuracy: 0.625\n",
      "Results for predicting being P for  Est: 10 / Depth: 20 ----- Precision: 0.619 / Recall: 0.913 / Accuracy: 0.612\n",
      "Results for predicting being I for  Est: 10 / Depth: 30 ----- Precision: 0.76 / Recall: 0.997 / Accuracy: 0.759\n",
      "Results for predicting being N for  Est: 10 / Depth: 30 ----- Precision: 0.876 / Recall: 1.0 / Accuracy: 0.876\n",
      "Results for predicting being F for  Est: 10 / Depth: 30 ----- Precision: 0.662 / Recall: 0.754 / Accuracy: 0.656\n",
      "Results for predicting being P for  Est: 10 / Depth: 30 ----- Precision: 0.634 / Recall: 0.872 / Accuracy: 0.613\n",
      "Results for predicting being I for  Est: 10 / Depth: None ----- Precision: 0.787 / Recall: 0.953 / Accuracy: 0.763\n",
      "Results for predicting being N for  Est: 10 / Depth: None ----- Precision: 0.861 / Recall: 1.0 / Accuracy: 0.861\n",
      "Results for predicting being F for  Est: 10 / Depth: None ----- Precision: 0.61 / Recall: 0.824 / Accuracy: 0.627\n",
      "Results for predicting being P for  Est: 10 / Depth: None ----- Precision: 0.633 / Recall: 0.727 / Accuracy: 0.584\n",
      "Results for predicting being I for  Est: 50 / Depth: 10 ----- Precision: 0.771 / Recall: 1.0 / Accuracy: 0.771\n",
      "Results for predicting being N for  Est: 50 / Depth: 10 ----- Precision: 0.844 / Recall: 1.0 / Accuracy: 0.844\n",
      "Results for predicting being F for  Est: 50 / Depth: 10 ----- Precision: 0.62 / Recall: 0.944 / Accuracy: 0.656\n",
      "Results for predicting being P for  Est: 50 / Depth: 10 ----- Precision: 0.599 / Recall: 1.0 / Accuracy: 0.599\n",
      "Results for predicting being I for  Est: 50 / Depth: 20 ----- Precision: 0.769 / Recall: 1.0 / Accuracy: 0.769\n",
      "Results for predicting being N for  Est: 50 / Depth: 20 ----- Precision: 0.87 / Recall: 1.0 / Accuracy: 0.87\n",
      "Results for predicting being F for  Est: 50 / Depth: 20 ----- Precision: 0.653 / Recall: 0.902 / Accuracy: 0.696\n",
      "Results for predicting being P for  Est: 50 / Depth: 20 ----- Precision: 0.616 / Recall: 0.995 / Accuracy: 0.621\n",
      "Results for predicting being I for  Est: 50 / Depth: 30 ----- Precision: 0.765 / Recall: 1.0 / Accuracy: 0.765\n",
      "Results for predicting being N for  Est: 50 / Depth: 30 ----- Precision: 0.864 / Recall: 1.0 / Accuracy: 0.864\n",
      "Results for predicting being F for  Est: 50 / Depth: 30 ----- Precision: 0.713 / Recall: 0.854 / Accuracy: 0.728\n",
      "Results for predicting being P for  Est: 50 / Depth: 30 ----- Precision: 0.608 / Recall: 0.988 / Accuracy: 0.613\n",
      "Results for predicting being I for  Est: 50 / Depth: None ----- Precision: 0.759 / Recall: 0.999 / Accuracy: 0.759\n",
      "Results for predicting being N for  Est: 50 / Depth: None ----- Precision: 0.852 / Recall: 1.0 / Accuracy: 0.852\n",
      "Results for predicting being F for  Est: 50 / Depth: None ----- Precision: 0.646 / Recall: 0.873 / Accuracy: 0.685\n",
      "Results for predicting being P for  Est: 50 / Depth: None ----- Precision: 0.631 / Recall: 0.934 / Accuracy: 0.628\n",
      "Results for predicting being I for  Est: 100 / Depth: 10 ----- Precision: 0.78 / Recall: 1.0 / Accuracy: 0.78\n",
      "Results for predicting being N for  Est: 100 / Depth: 10 ----- Precision: 0.847 / Recall: 1.0 / Accuracy: 0.847\n",
      "Results for predicting being F for  Est: 100 / Depth: 10 ----- Precision: 0.59 / Recall: 0.976 / Accuracy: 0.633\n",
      "Results for predicting being P for  Est: 100 / Depth: 10 ----- Precision: 0.617 / Recall: 1.0 / Accuracy: 0.617\n",
      "Results for predicting being I for  Est: 100 / Depth: 20 ----- Precision: 0.775 / Recall: 1.0 / Accuracy: 0.775\n",
      "Results for predicting being N for  Est: 100 / Depth: 20 ----- Precision: 0.863 / Recall: 1.0 / Accuracy: 0.863\n",
      "Results for predicting being F for  Est: 100 / Depth: 20 ----- Precision: 0.647 / Recall: 0.923 / Accuracy: 0.697\n",
      "Results for predicting being P for  Est: 100 / Depth: 20 ----- Precision: 0.606 / Recall: 0.999 / Accuracy: 0.606\n",
      "Results for predicting being I for  Est: 100 / Depth: 30 ----- Precision: 0.759 / Recall: 1.0 / Accuracy: 0.759\n",
      "Results for predicting being N for  Est: 100 / Depth: 30 ----- Precision: 0.86 / Recall: 1.0 / Accuracy: 0.86\n",
      "Results for predicting being F for  Est: 100 / Depth: 30 ----- Precision: 0.695 / Recall: 0.884 / Accuracy: 0.727\n",
      "Results for predicting being P for  Est: 100 / Depth: 30 ----- Precision: 0.604 / Recall: 0.998 / Accuracy: 0.606\n",
      "Results for predicting being I for  Est: 100 / Depth: None ----- Precision: 0.765 / Recall: 0.999 / Accuracy: 0.765\n",
      "Results for predicting being N for  Est: 100 / Depth: None ----- Precision: 0.865 / Recall: 1.0 / Accuracy: 0.865\n",
      "Results for predicting being F for  Est: 100 / Depth: None ----- Precision: 0.683 / Recall: 0.875 / Accuracy: 0.711\n",
      "Results for predicting being P for  Est: 100 / Depth: None ----- Precision: 0.604 / Recall: 0.981 / Accuracy: 0.607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def rfClassifier_GridSearch(X_Features, dataset_PD, test_Szie, predict_Lable, n_est, depth, is_print = True,):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_Features, dataset_PD, test_size=test_Szie) # 20% of our dataset is test set\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, max_depth=depth ,n_jobs=-1)#Max depth of tree is 20\n",
    "    rf_model = rf.fit(X_train, Y_train)\n",
    "    #sorted(zip(rf_model.feature_importances_, X_train.columns), reverse=True)[0:10] #List top 10 feature importances\n",
    "    Y_pred = rf_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(Y_test, Y_pred, pos_label=predict_Lable, average='binary')\n",
    "    if is_print:\n",
    "        print('Results for predicting being ' + predict_Lable + ' for '  ,'Est: {} / Depth: {} ----- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "                                                        n_est,\n",
    "                                                        depth,\n",
    "                                                        round(precision, 3),\n",
    "                                                        round(recall, 3), \n",
    "                                                        round((Y_pred==Y_test).sum() / len(Y_pred),3)))\n",
    "    return([precision, recall, fscore, support])\n",
    "\n",
    "\n",
    "X_Features = pd.DataFrame(full_Lem_tfidf.toarray())\n",
    "\n",
    "for n_est in [10, 50, 100]:\n",
    "    for depth in [10, 20, 30, None]:\n",
    "        rfClassifier_GridSearch(X_Features, mbti_Dataset['IE'], 0.2, 'I',n_est, depth)\n",
    "        rfClassifier_GridSearch(X_Features, mbti_Dataset['NS'], 0.2, 'N',n_est, depth)\n",
    "        rfClassifier_GridSearch(X_Features, mbti_Dataset['FT'], 0.2, 'F',n_est, depth)\n",
    "        rfClassifier_GridSearch(X_Features, mbti_Dataset['PJ'], 0.2, 'P',n_est, depth)\n"
   ]
  },
  {
   "source": [
    "Evaluate Random Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.229437      0.028390         0.160970        0.015081   \n",
       "11     140.384429     10.415539         1.838482        0.198458   \n",
       "7       61.349528      0.319875         1.198994        0.112245   \n",
       "4       48.727883      0.774539         1.041813        0.022974   \n",
       "8      121.526988      0.669293         2.227245        0.189642   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "0               30                 10   \n",
       "11            None                300   \n",
       "7               90                150   \n",
       "4               60                150   \n",
       "8               90                300   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "0      {'max_depth': 30, 'n_estimators': 10}           0.771182   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.770605   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.770029   \n",
       "4     {'max_depth': 60, 'n_estimators': 150}           0.770605   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.770029   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.774640           0.772334           0.768876   \n",
       "11           0.770605           0.770605           0.769452   \n",
       "7            0.770605           0.770605           0.769452   \n",
       "4            0.769452           0.771182           0.769452   \n",
       "8            0.770029           0.771182           0.769452   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.767147         0.770836        0.002619                1  \n",
       "11           0.770605         0.770375        0.000461                2  \n",
       "7            0.770605         0.770259        0.000461                3  \n",
       "4            0.770029         0.770144        0.000672                4  \n",
       "8            0.770029         0.770144        0.000565                4  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_max_depth</th>\n      <th>param_n_estimators</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.229437</td>\n      <td>0.028390</td>\n      <td>0.160970</td>\n      <td>0.015081</td>\n      <td>30</td>\n      <td>10</td>\n      <td>{'max_depth': 30, 'n_estimators': 10}</td>\n      <td>0.771182</td>\n      <td>0.774640</td>\n      <td>0.772334</td>\n      <td>0.768876</td>\n      <td>0.767147</td>\n      <td>0.770836</td>\n      <td>0.002619</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>140.384429</td>\n      <td>10.415539</td>\n      <td>1.838482</td>\n      <td>0.198458</td>\n      <td>None</td>\n      <td>300</td>\n      <td>{'max_depth': None, 'n_estimators': 300}</td>\n      <td>0.770605</td>\n      <td>0.770605</td>\n      <td>0.770605</td>\n      <td>0.769452</td>\n      <td>0.770605</td>\n      <td>0.770375</td>\n      <td>0.000461</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>61.349528</td>\n      <td>0.319875</td>\n      <td>1.198994</td>\n      <td>0.112245</td>\n      <td>90</td>\n      <td>150</td>\n      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n      <td>0.770029</td>\n      <td>0.770605</td>\n      <td>0.770605</td>\n      <td>0.769452</td>\n      <td>0.770605</td>\n      <td>0.770259</td>\n      <td>0.000461</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>48.727883</td>\n      <td>0.774539</td>\n      <td>1.041813</td>\n      <td>0.022974</td>\n      <td>60</td>\n      <td>150</td>\n      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n      <td>0.770605</td>\n      <td>0.769452</td>\n      <td>0.771182</td>\n      <td>0.769452</td>\n      <td>0.770029</td>\n      <td>0.770144</td>\n      <td>0.000672</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>121.526988</td>\n      <td>0.669293</td>\n      <td>2.227245</td>\n      <td>0.189642</td>\n      <td>90</td>\n      <td>300</td>\n      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n      <td>0.770029</td>\n      <td>0.770029</td>\n      <td>0.771182</td>\n      <td>0.769452</td>\n      <td>0.770029</td>\n      <td>0.770144</td>\n      <td>0.000565</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators' : [10, 150, 300],\n",
    "        'max_depth' : [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)#cv=5 meand 5 folde validation\n",
    "gs_fit = gs.fit(full_Lem_tfidf, mbti_Dataset['IE'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9        5.555741      0.152567         0.145610        0.008649   \n",
       "3        3.167928      0.094107         0.131447        0.005139   \n",
       "6        4.013665      0.037309         0.136834        0.006226   \n",
       "0        1.725784      0.039591         0.151995        0.024345   \n",
       "10      80.572718      0.898699         1.205576        0.079296   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "9             None                 10   \n",
       "3               60                 10   \n",
       "6               90                 10   \n",
       "0               30                 10   \n",
       "10            None                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "9    {'max_depth': None, 'n_estimators': 10}           0.786744   \n",
       "3      {'max_depth': 60, 'n_estimators': 10}           0.773487   \n",
       "6      {'max_depth': 90, 'n_estimators': 10}           0.767723   \n",
       "0      {'max_depth': 30, 'n_estimators': 10}           0.770605   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.770029   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "9            0.776369           0.770029           0.756772   \n",
       "3            0.771758           0.772334           0.771758   \n",
       "6            0.775216           0.781556           0.766571   \n",
       "0            0.773487           0.768876           0.769452   \n",
       "10           0.771758           0.770605           0.768876   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "9            0.774640         0.772911        0.009747                1  \n",
       "3            0.769452         0.771758        0.001314                2  \n",
       "6            0.765994         0.771412        0.006063                3  \n",
       "0            0.771182         0.770720        0.001606                4  \n",
       "10           0.770605         0.770375        0.000936                5  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_max_depth</th>\n      <th>param_n_estimators</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>5.555741</td>\n      <td>0.152567</td>\n      <td>0.145610</td>\n      <td>0.008649</td>\n      <td>None</td>\n      <td>10</td>\n      <td>{'max_depth': None, 'n_estimators': 10}</td>\n      <td>0.786744</td>\n      <td>0.776369</td>\n      <td>0.770029</td>\n      <td>0.756772</td>\n      <td>0.774640</td>\n      <td>0.772911</td>\n      <td>0.009747</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.167928</td>\n      <td>0.094107</td>\n      <td>0.131447</td>\n      <td>0.005139</td>\n      <td>60</td>\n      <td>10</td>\n      <td>{'max_depth': 60, 'n_estimators': 10}</td>\n      <td>0.773487</td>\n      <td>0.771758</td>\n      <td>0.772334</td>\n      <td>0.771758</td>\n      <td>0.769452</td>\n      <td>0.771758</td>\n      <td>0.001314</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.013665</td>\n      <td>0.037309</td>\n      <td>0.136834</td>\n      <td>0.006226</td>\n      <td>90</td>\n      <td>10</td>\n      <td>{'max_depth': 90, 'n_estimators': 10}</td>\n      <td>0.767723</td>\n      <td>0.775216</td>\n      <td>0.781556</td>\n      <td>0.766571</td>\n      <td>0.765994</td>\n      <td>0.771412</td>\n      <td>0.006063</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1.725784</td>\n      <td>0.039591</td>\n      <td>0.151995</td>\n      <td>0.024345</td>\n      <td>30</td>\n      <td>10</td>\n      <td>{'max_depth': 30, 'n_estimators': 10}</td>\n      <td>0.770605</td>\n      <td>0.773487</td>\n      <td>0.768876</td>\n      <td>0.769452</td>\n      <td>0.771182</td>\n      <td>0.770720</td>\n      <td>0.001606</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>80.572718</td>\n      <td>0.898699</td>\n      <td>1.205576</td>\n      <td>0.079296</td>\n      <td>None</td>\n      <td>150</td>\n      <td>{'max_depth': None, 'n_estimators': 150}</td>\n      <td>0.770029</td>\n      <td>0.771758</td>\n      <td>0.770605</td>\n      <td>0.768876</td>\n      <td>0.770605</td>\n      <td>0.770375</td>\n      <td>0.000936</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators' : [10, 150, 300],\n",
    "        'max_depth' : [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)#cv=5 meand 5 folde validation\n",
    "gs_fit = gs.fit(full_Lem_CV, mbti_Dataset['IE'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "source": [
    "Gradient boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "def GBoosting_GridSearch(X_Features, dataset_PD, test_Szie, predict_Lable, n_est, depth, lr ,is_print = True,):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_Features, dataset_PD, test_size=test_Szie) # 20% of our dataset is test set\n",
    "    gb = GradientBoostingClassifier(n_estimators=n_est, max_depth=depth ,learning_rate=lr)#Max depth of tree is 20\n",
    "    gb_model = gb.fit(X_train, Y_train)\n",
    "    #sorted(zip(gb_model.feature_importances_, X_train.columns), reverse=True)[0:10] #List top 10 feature importances\n",
    "    Y_pred = gb_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(Y_test, Y_pred, pos_label=predict_Lable, average='binary')\n",
    "    if is_print:\n",
    "        print('Results for predicting being ' + predict_Lable + ' for '  ,'Est: {} / Depth: {} / LearningRate : {} ----- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "                                                        n_est,\n",
    "                                                        depth,\n",
    "                                                        lr,\n",
    "                                                        round(precision, 3),\n",
    "                                                        round(recall, 3), \n",
    "                                                        round((Y_pred==Y_test).sum() / len(Y_pred),3)))\n",
    "    return([precision, recall, fscore, support])\n",
    "\n",
    "\n",
    "X_Features = pd.DataFrame(full_Lem_tfidf.toarray())\n",
    "\n",
    "for n_est in [50, 100, 150]:\n",
    "    for depth in [3, 7, 11, 15]:\n",
    "        for lr in [0.01, 0.1, 1]:\n",
    "            GBoosting_GridSearch(X_Features, mbti_Dataset['IE'], 0.2, 'I',n_est, depth, lr)\n",
    "            GBoosting_GridSearch(X_Features, mbti_Dataset['NS'], 0.2, 'N',n_est, depth, lr)\n",
    "            GBoosting_GridSearch(X_Features, mbti_Dataset['FT'], 0.2, 'F',n_est, depth, lr)\n",
    "            GBoosting_GridSearch(X_Features, mbti_Dataset['PJ'], 0.2, 'P',n_est, depth, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "param = {'n_estimators' : [50, 100, 150],\n",
    "        'max_depth' : [7, 11, 15],\n",
    "        'Learning_rate' : [0.1]}\n",
    "\n",
    "gs = GridSearchCV(gb, param, cv=5)#cv=5 meand 5 folde validation\n",
    "gs_fit = gs.fit(full_Lem_CV, mbti_Dataset['IE'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[0:5]"
   ]
  }
 ]
}